{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science en pratique\n",
    "\n",
    "Arthur Llau, arthur@flowlity.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cours 4: Model Evaluation, Selection & Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Objectif du cours:\n",
    "\n",
    "-  Vu d'ensemble des fonctions d'évaluation\n",
    "-  Méthode de sélection de modèles\n",
    "-  Présenter rapidemment les hyperparamètres important de quelques algorithmes connus.\n",
    "-  Optimisation de paramètres\n",
    "-  Sauvegarde des modèles\n",
    "-  TP de mise en pratique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1 - Fonctions d'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La majorité des fonctions d'évaluation présentées ci-dessous sont disponible dans **sklearn** ou **scipy**, néanmoins, il est important de savoir les recoder car ils peut arriver que les résultats ne soient pas ceux attendus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1 - Fonctions d'évaluation pour la régréssion\n",
    "\n",
    "Il existe plusieurs façons de mesurer les erreurs de prédictions pour un problème de régression. Quelques-une des fonctions d'évaluation pour ce type de problème sont présentées ci-dessous. Cependant, il en existe beaucoup d'autres selon l'interprétabilité que l'on souhaite donner à nos résultats. \n",
    "\n",
    "Tout dépend du problème à résoudre, et de ce qu'on veut en tirer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.1 - Mean Error (MAE)\n",
    "\n",
    "Les fonctions d'erreur moyenne représentent la moyenne des écart entre les prédictions et les observation selon une certaine contrainte. C'est une métrique facilement interprétable. Il en existe plusieurs versions, voici les plus célèbres :\n",
    "\n",
    "- Absolute : ${\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-\\hat{y}_{i}\\right|}{n}}}$\n",
    "\n",
    "- Square :  ${\\displaystyle \\mathrm {MSE} ={\\frac {\\sum _{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^2}{n}}}$\n",
    "\n",
    "- Percentage :  ${\\displaystyle {\\mbox{MAPE}}={\\frac {100}{n}}\\sum _{t=1}^{n}\\left|{\\frac {y_{i}-\\hat{y}_{t}}{y_{i}}}\\right|} $\n",
    "\n",
    "Plus l'erreur est faible, plus le modèle est efficace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.2 R2\n",
    "\n",
    "Le $${\\displaystyle R^{2}}$$ ou coefficient de détermination est une mesure de la qualité de la prédiction d'une régression linéaire.\n",
    "\n",
    "Il est défini comme le rapport entre la variance expliquée et la variance totale :\n",
    "\n",
    "$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=0}^{n - 1} (y_i - \\hat{y}_i)^2}{\\sum_{i=0}^{n - 1} (y_i - \\bar{y})^2}$\n",
    "\n",
    "C'est une mesure d'erreur facilement intérprétable, plus il y a de variables explicative plus le $R^{2}$ augmente. Le meilleur score possible est de 1 et, il peut être négatif si le modèle est vraiment mal choisi ou si il n'y a pas de variables explicatives. \n",
    "Cette métrique est utile pour donner de l'explicabilité.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2 - Fonctions d'évaluation pour la classification binaire.\n",
    "\n",
    "Pour évaluer les performances d'un classifieur binaire, il existe quelques fonctions d'évalution importantes. La plus simple est la mesure de précision, c'est à dire la somme des erreurs (1 si je me trompe, 0 sinon), néanmoins, en pratique on préfère utiliser l'erreur AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> voir pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2.2 - ROC-AUC\n",
    "Pour les erreurs commises par la classification binaire on peut définir les résultats suivant:<img src=\"TFP.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Définition** (Courbe ROC)*: On suppose que Y est la variable aléatoire des scores des expériences qui ont réussi. X est celle des scores des expériences qui ont échoué. On suppose également que tous les scores sont indépendants. On note $F_X$ et $F_Y$ les fonctions de répartition de ces variables. On définit en fonction d’un seuil $s \\in \\mathbb{R}$:\n",
    "    $$R(s) = 1 - F_Y(s)$$\n",
    "    $$E(s) = 1 - F_X(s)$$\n",
    "\n",
    "La courbe ROC est le graphe $ \\{E(s),R(s)\\}$ lorsque $s$ varie dans $\\mathbb{R}$.\n",
    "\n",
    "\n",
    "$VP(s)$ désigne les VP au-dessus du seuil $s$, avec les notations VP, FP, FN, VN, cela revient à :\n",
    "\n",
    "\n",
    "$\\begin{eqnarray*} E(s) &=& 1 - \\frac{ VP(s) } { VP(s) + VN(s) } \\\\ R(s) &=& 1 - \\frac{ FN(s) } { FP(s) + FN(s) } \\end{eqnarray*}$\n",
    "\n",
    "\n",
    "En faisant varier $s$ on obtient alors la courbe ROC pour le modèle choisi.\n",
    "\n",
    "*(voir http://www.xavierdupre.fr, site que je vous conseille par ailleurs.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "L'AUC n'est autre que l'aire sous cette courbe, si elle est égale à 1 le modèle ne se trompe jamais.\n",
    "<img src=\"rocauc.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2.3 - Log Loss\n",
    "\n",
    "Perte de la régréssion logistique, elle est définit par les probabilités estimées tel qu'avec $ p = \\operatorname{Pr}(y = 1)$ on a :\n",
    "\n",
    "\n",
    "$L_{\\log}(y, p) = -\\log \\operatorname{Pr}(y|p) = -(y \\log (p) + (1 - y) \\log (1 - p))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2 - Séléction de modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bien choisir le ou les modèle(s) à utiliser n'est pas une chose aisée. Cependant avec de la pratique on sait rapidemment vers quelle famille de modèles se tourner. Une manière de comparer des modèles est de comparer l'erreur de ceux-ci sur différents sous-ensemble des données. Pour ce faire, il existe plusieurs techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1 - Train test split\n",
    "\n",
    "Comme nous l'avons vu dans les cours précédents, une bonne méthode pour évaluer les performance d'un modèle sur un jeu de données et de séparer le jeu d'apprentissage en deux sous-ensemble, un d'apprentissage et un de validation.\n",
    "La fonction **train_test_split** de **sklearn** permet de réaliser cette échantillonnage de manière aléatoire. Un bon ratio est le 80/20. \n",
    "<img src=\"train_test_split.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cependant, ne peut-on pas aller plus loin ? Ne pourrait-on pas utiliser cette séparation des données pour faire le meilleur modèle possible, on pourrait alors essayer différents choix de paramètres, ou bien regarder la robustesse du modèle? C'est sur cela que repose le principe de la validation croisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2 - K-folds Cross Validation.\n",
    "\n",
    "La méthode des K-fold permet de divisé l'échantillon K en sous-ensemble de tailles égales, dont l'un est utilisé pour la prévision et les K-1 restants pour l'estimation du modèle. La fonction **KFold** de **sklearn** permet de réaliser cette opération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La notion de cross validation, validation croisée en français, correspond à l'idée d'évaluer le modèle sur plusieurs sous-ensemble du jeu de données afin d'avoir une observation moyenne des performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "La méthode **cross_val_score** de **sklearn** permet d'évaluer les performances d'un modèle selon une fonction d'évaluation et un nombre de folds choisi. Plus, il y aura de sous-ensemble plus le modèle sera robuste et son score sera, selon sa variance, le plus proche de la réalité. On peut alors, pour un découpage fixé, comparer plusieurs modèles grâce à leur performance sur une K-FoldCV. K=5 ou 10, permet d'établir de bons résultats.\n",
    "\n",
    "<img src=\"kfolds.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Validation dans le cas des séries temporelles.\n",
    "\n",
    "Qui dit temporalité, dit interdiction de jouer avec de l'aléatoire. Pour se faire on va utiliser les concepts précédents mais pour les adaptés à la notion de temporalité. On parlera à alors de Time Series Cross Validation par exemple, TimeSeriesSplit sur scikit-learn. Noté qu'une bonne façon de valider également ces résultats et de constituer un ensemble de validation comportant les mêmes périodes que le jeu de test futur. En particulier dans le cas de forte saisonnalité.\n",
    "\n",
    "<img src=\"cv_ts.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un mix des concepts précédents peut également être fait dans le cas où l'on cherche à prédire de multiples séries temporelles, c'est-à-dire à la fois prédire le futur et à la fois prédire des séries non nécéssairement observées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il existe bien d'autre façon de choisir son modèle, nous verrons cela plus en détails plus tard dans l'année."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3 - Hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1 Hyperparamètre propre à Sklearn\n",
    "\n",
    "Dans la majorité des modèles disponibles dans sklearn on trouve les paramètres globaux suivants:\n",
    "- **n_jobs** : nombre de coeurs à utiliser pour effectuer les calculs, dépend de votre cpu.\n",
    "- **verbose** : affichage du déroulement des calculs, 0 = silent. \n",
    "- **random_state** : si la méthode repose sur de l'aléatoire, fixe le générateur pour reproduire les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2 -Arbres CART\n",
    "\n",
    "Introduit par Breiman en 1984 : https://rafalab.github.io/pages/649/section-11.pdf. \n",
    "\n",
    "Principe : construire un arbre de décision ou chaque noeud est une question binaire.\n",
    "\n",
    "Sous sklearn le modèle est dénommé DecisionTreeClassifier & DecisionTreeRegressor, les hyperparamètres à connaitre sont les suivants:\n",
    "- **criterion** : Critère de découpe des noeuds, Gini pour la précision, Entropy pour un gain d'information \n",
    "- **max_depth** : profondeur maximale de l'arbre\n",
    "- **min_samples_split** : Nombre minimal d'observations pour séparer un noeud\n",
    "- **max_features** : Nombre de features à considérer pour la meilleure séparation d'un noeud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.3 - Méthodes d'ensemble\n",
    "\n",
    "Méthodes non paramètrique : Random Forest, GBT, ExtraTrees ...\n",
    "\n",
    "De manière général, les méthodes d'ensemble sont constituées de la manière suivante:\n",
    "-  Un espace d'hyphotèse $\\mathcal{H}$\n",
    "-  Des weak learners $h_t$ efficace sur $\\mathcal{H}$\n",
    "-  Les combiner pour obtenir un big learner $H$\n",
    "\n",
    "On ne s'intéresse ici qu'au weak learners étant des arbres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.3.1 Random Forest\n",
    "\n",
    "Introduit par Breiman en 1999 : https://www.stat.berkeley.edu/~breiman/random-forests.pdf. \n",
    "\n",
    "Principe : ensemble d'arbres décisionnel où a été introduit de l'aléatoire. Le résultat final est obtenu par vote majoritaire ou moyenne. (Tree bagging + feature sampling)\n",
    "\n",
    "Sous sklearn le modèle est dénommé RandomForestClassifier & RandomForestRegressor, il y a deux sortes d'hyperparamètres, ceux relatif aux arbres utilisés et ceux  de la forêt. Ceux des arbres sont ceux cités plus haut, l'hyperparamètre le plus important pour les random forest est le nombre d'arbre utilisés : **n_estimators**. \n",
    "La précision a tendance à augmenter quand le nombre d'arbres augmente, néanmoins, le temps de calcul est de plus en plus long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.3.2 - Gradient Tree Boosting \n",
    "\n",
    "Introduit par Friedman en 1999 : https://statweb.stanford.edu/~jhf/ftp/trebst.pdf.\n",
    "\n",
    "Principe : Boosting + descente de gradient. C'est-à-dire qu'on combine les arbres de façon pondérée en optimisant les poids par descente de gradient.\n",
    "\n",
    "Sous sklearn le modèle est dénommé GradientTreeClassifier & GradientTreeRegressor. \n",
    "Comme pour les forêts, il y a les paramètres propres aux arbres, et ceux au boosting qui sont les suivants (en particulier pour Xgboost & cie):\n",
    "- Le premier choix c'est la loss, i.e. la fonction objective qui résoud notre problème.\n",
    "\n",
    "<img src=\"boosting_loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensuite on explore l'immensité des paramètres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hp.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.4 - SVM\n",
    "\n",
    "Introduit par Vapnik en 1963 : http://web.cs.iastate.edu/~cs573x/vapnik-portraits1963.pdf.\n",
    "\n",
    "Principe : construire un hyperplan séparateur dans l’espace des observations, c’est-à-dire de séparer linéairement les données des différentes classes. (Et surtout le génial Kernel Trick pour les cas non linéairement séparable)\n",
    "\n",
    "\n",
    "Sous sklearn le modèle est dénommé SVC & SVR. Les hyperparamètres sont les suivants :\n",
    "- **kernel** : Noyau utilisé, linéaire si cas linéaire etc. \n",
    "- **c** : Pénalité du terme d'erreur.\n",
    "- **epsilon** : taille du tube où la pénalité n'est pas appliquée.\n",
    "- **gamma** : coefficient du noyau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.5 - Modèles linéaires\n",
    "\n",
    "On retrouve les paramètres suivant selon les cas (Ridge, Lasso, ElasticNet ...):\n",
    "- **lambda** : pénalité $L^1$.\n",
    "- **alpha** : pénalité $L^2$.\n",
    "- **fit_intercept** : tenir compte de l'intercept ou non"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4 - Optimisation des hyperparamètres aka tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tuning = Optimisation des hyperparamètres, plus ils sont bien choisi plus le modèle est performant.\n",
    "<img src=\"voiture.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Les librairies suivantes permettent d'effectuer des recherche d'hyperparamètres optimaux:\n",
    "- Sklearn\n",
    "- HyperOpt\n",
    "- Spearmint\n",
    "- BayesOpt\n",
    "\n",
    "\n",
    "Ici, nous ne verrons que les méthodes liées à sklearn, libre à vous d'aller explorer les autres librairies.\n",
    "Personnellement, j'utilise scikit-opt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.1 - Brut Force\n",
    "\n",
    "Idée naïve de tester pleins de paramètres à la main à tour de rôle. Cependant, les résultats peuvent varier et ne pas être stables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 - Le principe de la gridsearch\n",
    "\n",
    "L'idée est d'obtenir les paramètres impliquant les meilleures performances possible du modèle grâce à une validation croisée.\n",
    "\n",
    "<img src=\"gridsearch.png\">\n",
    "\n",
    "L'algorithme effectue pour chaque n-uplet de paramètres un calcul des performances du modèle sur une K-CV. \n",
    "A la fin, il récupère les paramètres ayant obtenu le meilleur score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.3 - Exhaustive GridSearch\n",
    "\n",
    "La fonction **GridSearchCV** de **sklearn** permet d'effectuer cette recherche d'hyperparamètres, elle prend en entrée : \n",
    "- L'estimateur\n",
    "- Un espace de paramètres, i.e., une liste de valeurs possible pour chaque paramètre\n",
    "- Un nombre de folds pour la CV\n",
    "- Une fonction d'évaluation\n",
    "- Et d'autres paramètres pour le sampling ..\n",
    "\n",
    "L'exhaustive gridsearch correspond à une grille de test, en gros on teste toutes les combinaisons possibles.\n",
    "\n",
    "Plus il y a de paramètres et de folds, plus le calcul sera long, par exemple, pour 3 paramètres à 3 choix possibles et 3 folds on doit réaliser 81 fitting... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.4 - Optimisation aléatoire\n",
    "\n",
    "La méthode précédente est bien si l'on sait où chercher, ce qui n'est pas toujours le cas. On peut alors utiliser une gridsearch avec un espace de paramètres définit comme les distributions des hyperparamètres et en choisissant un nombre d'itérations de recherche maximal.\n",
    "Par exemple, le nombre d'estimateurs du forêt peut être compris entre 100 et 10000, plutôt que de chercher une valeur exact, on peut tirer des valeurs dans une uniforme discrète entre ces deux valeurs. \n",
    "\n",
    "**RandomizedGridSearch** est une implémentation de cet algorithme.\n",
    "\n",
    "On l'utilise généralement pour trouver un ordre de grandeur des valeurs des paramètres puis on effectue une gridsearch exhaustive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.4 - Autres méthodes \n",
    "\n",
    "Dans la littérature il existe beaucoup d'autres techniques de recherche d'hyperparamètres. \n",
    "\n",
    "On retrouve notamment la recherche par Optimisation Bayésienne qui consiste à donner un prior de la fonction objectif puis à évaluer les probabilités de la distribution à posteriori grâce à des processus Gaussiens. Et enfin, estimer une fonction objective simple. (voir : https://arxiv.org/pdf/1206.2944.pdf). Nous ferons un exemple dans le tp.\n",
    "\n",
    "Il existe également des manières d'optimiser les hyperparamètres grâce à des descentes de gradient. (Voir les NNet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5 - Sauvegarde et réutilisation d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "X,y = fetch_california_housing()['data'],fetch_california_housing()['target']\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "#sauvegarde\n",
    "with open('classifieur.object', 'wb') as m:\n",
    "    pickle.dump(model, m)    \n",
    "\n",
    "#ouverture\n",
    "with open('classifieur.object', 'rb') as m:\n",
    "    model = pickle.load(m)\n",
    "    \n",
    "#Vous pouvez le réutiliser dans n'importe quel autre code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TP - Prédire le prix des maisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Variable cible : **SalePrice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1 - Analyse exploratoire\n",
    "\n",
    "**1.1** - Explorer les données des deux datasets. Variables manquantes, catégorielles ? Que pensez-vous des variables cibles ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2 - Feature engineering\n",
    "\n",
    "**2.1** - Que faire des valeurs manquantes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Normalement nous devrions, bien regarder les statistiques pécédentes, puis compléter les valeurs de manière intelligente. Faites le à la maison, nous faisons simple cette fois-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nan_filling(x):\n",
    "    if x.dtype == object:\n",
    "        return x.fillna(x.mode().values[0])\n",
    "    else:\n",
    "        return x.fillna(x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.2** - Utilisez des LabelEncoder pour gérer les variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in data.select_dtypes(object).columns :\n",
    "    \"\"\" ... \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** - Grâce à une matrice de corrélation déterminer les variables qui influencent les targets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.3** - Extrayez la variable cible, supprimer la variable Id, ainsi que la variable cible. Puis séparez en train et test (80/20) et séparez à nouveau en le train en jeu de validation et d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = ...\n",
    "data = data.drop(..., axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = #...\n",
    "X_train, X_valid, y_train, y_valid = #..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3 - Sélection de modèles\n",
    "\n",
    "Quels sont selon vous les modèles qui pourraient être efficace ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**3.1** - Construire une fonction **compute_evaluation** qui prend en entrée un dictionnaire de modèles (au choix) {'name':model}, et renvoie la moyenne et l'écart-type de leurs performances sur une cross validation à trois folds pour l'erreur MAPE. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "MAPE = make_scorer(mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Evaluation(models, X_train, y_train, metric = None):\n",
    "    \"\"\" models = {name: sklearn model}\n",
    "    for model in models:\n",
    "        models[model]['score'] = cross_val_score(models[model]['model'], X_train, y_train, cv=3,scoring=metric)\n",
    "        print(f\"{model}: {models[model]['score'].mean():.2f} +/- {models[model]['score'].std():.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "models ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Evaluation(models,  X_train, y_train, metric = MAPE) # Pourquoi la SVR est dans les choux ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**3.2** - Quels modèles choisir ? Evaluer leurs performances sur le jeu de validation et le jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4 - Optimisation du modèle\n",
    "\n",
    "**4.1** - Faites varier les principaux paramètres des modèle, et observer les performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**4.2** - Effectuer une recherche automatique des paramètres grâce à une des méthodes présentées plus haut, et tester un de vos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = ... \n",
    "\n",
    "params = {}\n",
    "\n",
    "grid = GridSearchCV(model,param_grid=params,cv=3, n_jobs=-1,verbose = 1)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print( 'Résultat de la grid search : {}'.format(grid.best_params_))\n",
    "\n",
    "##On peut récupérer le meilleur modèle : \n",
    "best = grid.best_estimator_\n",
    "\n",
    "print ('Performance du modèle optimisé validation:', mean_absolute_percentage_error(y_valid, best.predict(X_valid)))\n",
    "print ('Performance du modèle optimisé test:', mean_absolute_percentage_error(y_test, best.predict(X_test)))\n",
    "\n",
    "# Sacré amélioration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**4.3** : Tester Optuna avec l'algorithme de votre choix et observez les résultats sur le jeu de test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import trial\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        ...\n",
    "    }\n",
    "\n",
    "\n",
    "    model = ...\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    error = mean_absolute_percentage_error(y_valid, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "study = optuna.create_study()  \n",
    "study.optimize(objective, n_trials=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Erreur finale sur le jeu de test: {mean_absolute_percentage_error(y_test, y_pred):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_param_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
