{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 - Exercise 2: Fine-Tuning Fundamentals\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the concept and benefits of fine-tuning pretrained models\n",
    "- Learn how to adapt pretrained models to new tasks\n",
    "- Master techniques for freezing and unfreezing layers\n",
    "- Compare performance between training from scratch and fine-tuning\n",
    "- Implement progressive unfreezing strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Preparation\n",
    "\n",
    "We will work with a subset of CIFAR-10, focusing on distinguishing between animals (cats, dogs, birds, horses) and vehicles (cars, trucks, ships, planes). This binary classification task will demonstrate how pretrained models can be adapted to new problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     11\u001b[39m transform_test = transforms.Compose([\n\u001b[32m     12\u001b[39m     transforms.Resize(\u001b[32m224\u001b[39m),\n\u001b[32m     13\u001b[39m     transforms.ToTensor(),\n\u001b[32m     14\u001b[39m     transforms.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m],\n\u001b[32m     15\u001b[39m                        std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m])\n\u001b[32m     16\u001b[39m ])\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Download CIFAR-10 dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m trainset = \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m testset = torchvision.datasets.CIFAR10(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     22\u001b[39m                                       download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform_test)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# CIFAR-10 classes: 0=plane, 1=car, 2=bird, 3=cat, 4=deer, 5=dog, 6=frog, 7=horse, 8=ship, 9=truck\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Animals: 2(bird), 3(cat), 4(deer), 5(dog), 6(frog), 7(horse) -> label 0\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Vehicles: 0(plane), 1(car), 8(ship), 9(truck) -> label 1\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/data-science-practice--_liftEF-py3.13/lib/python3.13/site-packages/torchvision/datasets/cifar.py:66\u001b[39m, in \u001b[36mCIFAR10.__init__\u001b[39m\u001b[34m(self, root, train, transform, target_transform, download)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m.train = train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_integrity():\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/data-science-practice--_liftEF-py3.13/lib/python3.13/site-packages/torchvision/datasets/cifar.py:139\u001b[39m, in \u001b[36mCIFAR10.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_integrity():\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/data-science-practice--_liftEF-py3.13/lib/python3.13/site-packages/torchvision/datasets/utils.py:388\u001b[39m, in \u001b[36mdownload_and_extract_archive\u001b[39m\u001b[34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[32m    386\u001b[39m     filename = os.path.basename(url)\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m archive = os.path.join(download_root, filename)\n\u001b[32m    391\u001b[39m extract_archive(archive, extract_root, remove_finished)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/data-science-practice--_liftEF-py3.13/lib/python3.13/site-packages/torchvision/datasets/utils.py:127\u001b[39m, in \u001b[36mdownload_url\u001b[39m\u001b[34m(url, root, filename, md5, max_redirect_hops)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# download the file\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib.error.URLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[32m5\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/data-science-practice--_liftEF-py3.13/lib/python3.13/site-packages/torchvision/datasets/utils.py:30\u001b[39m, in \u001b[36m_urlretrieve\u001b[39m\u001b[34m(url, filename, chunk_size)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m urllib.request.urlopen(urllib.request.Request(url, headers={\u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total=response.length, unit=\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, unit_scale=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m         \u001b[38;5;28;01mwhile\u001b[39;00m chunk := \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     31\u001b[39m             fh.write(chunk)\n\u001b[32m     32\u001b[39m             pbar.update(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.6/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.6/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.6/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.6/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define data transformations\n",
    "# Note: Pretrained models expect specific input normalization\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),  # ResNet expects 224x224 images\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet statistics\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Download CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transform_test)\n",
    "\n",
    "# CIFAR-10 classes: 0=plane, 1=car, 2=bird, 3=cat, 4=deer, 5=dog, 6=frog, 7=horse, 8=ship, 9=truck\n",
    "# Animals: 2(bird), 3(cat), 4(deer), 5(dog), 6(frog), 7(horse) -> label 0\n",
    "# Vehicles: 0(plane), 1(car), 8(ship), 9(truck) -> label 1\n",
    "\n",
    "def create_binary_dataset(dataset, num_samples=2000):\n",
    "    \"\"\"Create a binary classification dataset: animals vs vehicles\"\"\"\n",
    "    animals = [2, 3, 4, 5, 6, 7]\n",
    "    vehicles = [0, 1, 8, 9]\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    samples_per_class = num_samples // 2\n",
    "    animal_count = 0\n",
    "    vehicle_count = 0\n",
    "    \n",
    "    for img, label in dataset:\n",
    "        if label in animals and animal_count < samples_per_class:\n",
    "            data.append(img)\n",
    "            labels.append(0)  # Animals = 0\n",
    "            animal_count += 1\n",
    "        elif label in vehicles and vehicle_count < samples_per_class:\n",
    "            data.append(img)\n",
    "            labels.append(1)  # Vehicles = 1\n",
    "            vehicle_count += 1\n",
    "            \n",
    "        if animal_count >= samples_per_class and vehicle_count >= samples_per_class:\n",
    "            break\n",
    "    \n",
    "    return torch.stack(data), torch.tensor(labels)\n",
    "\n",
    "# Create smaller datasets for faster training\n",
    "print(\"Creating binary classification datasets...\")\n",
    "train_data, train_labels = create_binary_dataset(trainset, num_samples=2000)\n",
    "test_data, test_labels = create_binary_dataset(testset, num_samples=400)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Class distribution - Train: Animals={sum(train_labels==0)}, Vehicles={sum(train_labels==1)}\")\n",
    "print(f\"Class distribution - Test: Animals={sum(test_labels==0)}, Vehicles={sum(test_labels==1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function to denormalize and display images\n",
    "def denormalize_image(img_tensor):\n",
    "    \"\"\"Denormalize image tensor for visualization\"\"\"\n",
    "    # ImageNet normalization parameters\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    # TODO: Denormalize the image tensor\n",
    "    # Hint: reversed_img = img * std + mean\n",
    "    denormalized = None\n",
    "    \n",
    "    return denormalized\n",
    "\n",
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "class_names = ['Animal', 'Vehicle']\n",
    "\n",
    "for i in range(8):\n",
    "    img, label = train_dataset[i]\n",
    "    \n",
    "    # Denormalize for display\n",
    "    img_display = denormalize_image(img)\n",
    "    if img_display is not None:\n",
    "        img_display = np.clip(img_display.permute(1, 2, 0).numpy(), 0, 1)\n",
    "    else:\n",
    "        img_display = np.zeros((224, 224, 3))\n",
    "    \n",
    "    ax = axes[i // 4, i % 4]\n",
    "    ax.imshow(img_display)\n",
    "    ax.set_title(f\"{class_names[label]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Training a Custom Model from Scratch\n",
    "\n",
    "First, let's establish a baseline by training a simple CNN from scratch. This will help us appreciate the benefits of fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"A simple CNN for binary classification\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # TODO: Define the convolutional layers\n",
    "        # Architecture: Conv(3->32) -> Conv(32->64) -> Conv(64->128)\n",
    "        # Use kernel_size=3, padding=1 for all conv layers\n",
    "        self.conv1 = None\n",
    "        self.conv2 = None\n",
    "        self.conv3 = None\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Calculate the size after convolutions and pooling\n",
    "        # Input: 224x224, after 3 pooling: 224/8 = 28\n",
    "        # TODO: Define fully connected layers\n",
    "        # fc1: (128 * 28 * 28) -> 256\n",
    "        # fc2: 256 -> 64\n",
    "        # fc3: 64 -> 2 (binary classification)\n",
    "        self.fc1 = None\n",
    "        self.fc2 = None\n",
    "        self.fc3 = None\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass\n",
    "        # Apply conv -> relu -> pool for each conv layer\n",
    "        # Then flatten and pass through FC layers with ReLU and dropout\n",
    "        \n",
    "        # Convolutional layers\n",
    "        x = None  # First conv block\n",
    "        x = None  # Second conv block\n",
    "        x = None  # Third conv block\n",
    "        \n",
    "        # Flatten\n",
    "        x = None\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = None  # fc1 with ReLU and dropout\n",
    "        x = None  # fc2 with ReLU and dropout\n",
    "        x = None  # fc3 (output)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test the model creation\n",
    "model_scratch = SimpleCNN().to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model_scratch.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=10, lr=0.001, model_name=\"Model\"):\n",
    "    \"\"\"Generic training function for any model\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # TODO: Implement the training step\n",
    "            # 1. Zero gradients\n",
    "            # 2. Forward pass\n",
    "            # 3. Calculate loss\n",
    "            # 4. Backward pass\n",
    "            # 5. Update weights\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = None  # Forward pass\n",
    "            loss = None  # Calculate loss\n",
    "            \n",
    "            if loss is not None:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss_avg = train_loss / len(train_loader)\n",
    "        train_acc = 100 * train_correct / train_total if train_total > 0 else 0\n",
    "        test_loss_avg = test_loss / len(test_loader)\n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        history['train_loss'].append(train_loss_avg)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss_avg)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"{model_name} - Epoch [{epoch+1}/{num_epochs}]: \"\n",
    "                  f\"Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "                  f\"Test Loss: {test_loss_avg:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the custom model from scratch\n",
    "print(\"Training custom CNN from scratch...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize and train the model\n",
    "model_scratch = SimpleCNN().to(device)\n",
    "history_scratch = None  # TODO: Call train_model with appropriate parameters\n",
    "\n",
    "if history_scratch:\n",
    "    print(f\"\\nFinal Test Accuracy (from scratch): {history_scratch['test_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Loading and Modifying a Pretrained Model\n",
    "\n",
    "Now, let's use a pretrained ResNet18 model. Pretrained models are trained on large datasets (like ImageNet with 1.2M images and 1000 classes) and have learned rich feature representations that can be transferred to new tasks.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Transfer Learning**: Using knowledge from one task to improve performance on another\n",
    "- **Feature Extraction**: Lower layers learn general features (edges, textures) that are useful across tasks\n",
    "- **Task-Specific Adaptation**: Only the final layers need to be modified for the new task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet18\n",
    "print(\"Loading pretrained ResNet18...\")\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Examine the model architecture\n",
    "print(f\"\\nOriginal ResNet18 architecture (last layers):\")\n",
    "print(f\"Average Pooling: {resnet18.avgpool}\")\n",
    "print(f\"Final FC Layer: {resnet18.fc}\")\n",
    "print(f\"Output features: {resnet18.fc.out_features}\")\n",
    "\n",
    "# TODO: Modify the final layer for binary classification\n",
    "# The original fc layer outputs 1000 classes (ImageNet)\n",
    "# We need to replace it with a layer that outputs 2 classes\n",
    "\n",
    "# Get the number of input features to the final layer\n",
    "num_features = resnet18.fc.in_features\n",
    "print(f\"\\nNumber of input features to final layer: {num_features}\")\n",
    "\n",
    "# TODO: Replace the final layer\n",
    "# Create a new Linear layer: num_features -> 2\n",
    "resnet18.fc = None\n",
    "\n",
    "# Move model to device\n",
    "model_pretrained = resnet18.to(device)\n",
    "\n",
    "print(f\"\\nModified final layer: {model_pretrained.fc}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model_pretrained.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model_pretrained.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Fine-Tuning with Frozen Layers\n",
    "\n",
    "When fine-tuning, we typically start by freezing the pretrained layers and only training the new final layer. This approach:\n",
    "1. Preserves the learned features from ImageNet\n",
    "2. Prevents overfitting on our small dataset\n",
    "3. Speeds up training significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model, freeze=True):\n",
    "    \"\"\"Freeze or unfreeze all layers except the final one\"\"\"\n",
    "    # TODO: Implement layer freezing\n",
    "    # Set requires_grad=freeze for all parameters except model.fc\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'fc' not in name:  # Don't freeze the final layer\n",
    "            param.requires_grad = None  # TODO: Set to appropriate value\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(f\"Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)\")\n",
    "    return model\n",
    "\n",
    "# Freeze the pretrained layers\n",
    "print(\"Freezing pretrained layers...\")\n",
    "model_frozen = models.resnet18(pretrained=True)\n",
    "model_frozen.fc = nn.Linear(model_frozen.fc.in_features, 2)\n",
    "model_frozen = model_frozen.to(device)\n",
    "\n",
    "model_frozen = freeze_layers(model_frozen, freeze=False)  # False means don't train them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with Frozen Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model with frozen layers\n",
    "print(\"\\nTraining with frozen pretrained layers...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "history_frozen = None  # TODO: Call train_model with appropriate parameters\n",
    "# Use a higher learning rate since we're only training the final layer\n",
    "\n",
    "if history_frozen:\n",
    "    print(f\"\\nFinal Test Accuracy (frozen layers): {history_frozen['test_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Progressive Unfreezing\n",
    "\n",
    "Progressive unfreezing is an advanced fine-tuning technique where we gradually unfreeze layers from top to bottom. This allows the model to adapt more specifically to our task while maintaining stability.\n",
    "\n",
    "### Strategy:\n",
    "1. Start with all layers frozen (except the final layer)\n",
    "2. Train for a few epochs\n",
    "3. Unfreeze the last few layers\n",
    "4. Continue training with a lower learning rate\n",
    "5. Optionally, unfreeze more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_groups(model):\n",
    "    \"\"\"Group ResNet18 layers for progressive unfreezing\"\"\"\n",
    "    # ResNet18 structure:\n",
    "    # - Initial layers: conv1, bn1, relu, maxpool\n",
    "    # - Layer1: 2 residual blocks\n",
    "    # - Layer2: 2 residual blocks\n",
    "    # - Layer3: 2 residual blocks\n",
    "    # - Layer4: 2 residual blocks\n",
    "    # - Final: avgpool, fc\n",
    "    \n",
    "    groups = [\n",
    "        ['conv1', 'bn1'],           # Group 0: Initial convolution\n",
    "        ['layer1'],                 # Group 1: First residual blocks\n",
    "        ['layer2'],                 # Group 2: Second residual blocks\n",
    "        ['layer3'],                 # Group 3: Third residual blocks\n",
    "        ['layer4'],                 # Group 4: Fourth residual blocks\n",
    "        ['fc']                      # Group 5: Final classifier\n",
    "    ]\n",
    "    return groups\n",
    "\n",
    "def unfreeze_groups(model, groups_to_unfreeze):\n",
    "    \"\"\"Unfreeze specific layer groups\"\"\"\n",
    "    groups = get_layer_groups(model)\n",
    "    \n",
    "    # TODO: Implement selective unfreezing\n",
    "    # First, freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = None  # TODO: Set to freeze\n",
    "    \n",
    "    # Then, unfreeze specified groups\n",
    "    for group_idx in groups_to_unfreeze:\n",
    "        if group_idx < len(groups):\n",
    "            for layer_name in groups[group_idx]:\n",
    "                for name, param in model.named_parameters():\n",
    "                    if layer_name in name:\n",
    "                        param.requires_grad = None  # TODO: Set to unfreeze\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(f\"Unfrozen groups: {groups_to_unfreeze}\")\n",
    "    print(f\"Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Progressive Unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progressive unfreezing experiment\n",
    "print(\"Progressive Unfreezing Experiment\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize a fresh pretrained model\n",
    "model_progressive = models.resnet18(pretrained=True)\n",
    "model_progressive.fc = nn.Linear(model_progressive.fc.in_features, 2)\n",
    "model_progressive = model_progressive.to(device)\n",
    "\n",
    "# Stage 1: Train only the final layer\n",
    "print(\"\\nStage 1: Training only the final layer\")\n",
    "model_progressive = unfreeze_groups(model_progressive, [5])  # Only fc layer\n",
    "\n",
    "# TODO: Train for 5 epochs with high learning rate\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_progressive.parameters()), lr=0.001)\n",
    "history_stage1 = None  # TODO: Implement training\n",
    "\n",
    "# Stage 2: Unfreeze layer4 (last residual blocks)\n",
    "print(\"\\nStage 2: Unfreezing layer4\")\n",
    "model_progressive = unfreeze_groups(model_progressive, [4, 5])  # layer4 + fc\n",
    "\n",
    "# TODO: Train for 5 more epochs with lower learning rate\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_progressive.parameters()), lr=0.0001)\n",
    "history_stage2 = None  # TODO: Implement training\n",
    "\n",
    "# Stage 3: Unfreeze layer3\n",
    "print(\"\\nStage 3: Unfreezing layer3\")\n",
    "model_progressive = unfreeze_groups(model_progressive, [3, 4, 5])  # layer3 + layer4 + fc\n",
    "\n",
    "# TODO: Train for 5 more epochs with even lower learning rate\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_progressive.parameters()), lr=0.00001)\n",
    "history_stage3 = None  # TODO: Implement training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Comparison and Analysis\n",
    "\n",
    "Let's compare the performance of different approaches to understand the benefits of fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(histories, labels):\n",
    "    \"\"\"Plot training histories for comparison\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    for history, label in zip(histories, labels):\n",
    "        if history:\n",
    "            ax1.plot(history['train_acc'], linestyle='--', alpha=0.7)\n",
    "            ax1.plot(history['test_acc'], label=f\"{label} (Test)\", linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy (%)')\n",
    "    ax1.set_title('Model Accuracy Comparison')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss\n",
    "    for history, label in zip(histories, labels):\n",
    "        if history:\n",
    "            ax2.plot(history['train_loss'], linestyle='--', alpha=0.7)\n",
    "            ax2.plot(history['test_loss'], label=f\"{label} (Test)\", linewidth=2)\n",
    "    \n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_title('Model Loss Comparison')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Create comparison plots\n",
    "histories = [history_scratch, history_frozen]  # Add more histories as available\n",
    "labels = ['From Scratch', 'Frozen Pretrained']\n",
    "\n",
    "plot_training_history(histories, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a performance summary table\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "print(\"\\nPerformance Summary\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# TODO: Evaluate each model and display results\n",
    "models_to_evaluate = [\n",
    "    (model_scratch, \"From Scratch\"),\n",
    "    (model_frozen, \"Frozen Pretrained\"),\n",
    "    (model_progressive, \"Progressive Unfreezing\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "for model, name in models_to_evaluate:\n",
    "    if model is not None:\n",
    "        try:\n",
    "            acc = evaluate_model(model, test_loader)\n",
    "            results.append((name, acc))\n",
    "            print(f\"{name:25s}: {acc:.2f}%\")\n",
    "        except:\n",
    "            print(f\"{name:25s}: Not trained\")\n",
    "\n",
    "# Identify best model\n",
    "if results:\n",
    "    best_model = max(results, key=lambda x: x[1])\n",
    "    print(f\"\\nBest performing model: {best_model[0]} ({best_model[1]:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
