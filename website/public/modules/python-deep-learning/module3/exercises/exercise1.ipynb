{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Exercise 1: Data Pipeline & Training Loop\n",
    "\n",
    "## Learning Objectives\n",
    "- Create simple datasets and split them into train/validation/test sets\n",
    "- Use DataLoader with different batch sizes\n",
    "- Implement a complete training loop from scratch\n",
    "- Compare different optimizers (SGD, Adam)\n",
    "- Evaluate models on train, validation, and test sets\n",
    "- Analyze the effect of different learning rates\n",
    "\n",
    "*Master the fundamentals of PyTorch training pipelines with simple examples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the test repository\n",
    "!git clone https://github.com/racousin/data_science_practice.git /tmp/tests 2>/dev/null || true\n",
    "\n",
    "# Import required modules\n",
    "import sys\n",
    "sys.path.append('/tmp/tests/tests/python_deep_learning')\n",
    "\n",
    "# Import the improved test utilities\n",
    "from test_utils import NotebookTestRunner, create_inline_test\n",
    "from module3.test_exercise1 import Exercise1Validator, EXERCISE1_SECTIONS\n",
    "\n",
    "# Create test runner and validator\n",
    "test_runner = NotebookTestRunner(\"module3\", 1)\n",
    "validator = Exercise1Validator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Creating a Simple Dataset\n",
    "\n",
    "Let's start by creating a simple synthetic dataset for regression. We'll generate data from a linear relationship with some noise:\n",
    "$$y = 2x + 1 + \\epsilon$$\n",
    "where $\\epsilon \\sim \\mathcal{N}(0, 0.1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a simple dataset with 100 samples\n",
    "# X_train should be a tensor of shape (100, 1) with values from -1 to 1\n",
    "# y_train should follow the relationship: y = 2*x + 1 + noise\n",
    "\n",
    "X_train = None  # Shape: (100, 1)\n",
    "y_train = None  # Shape: (100,) or (100, 1)\n",
    "\n",
    "# Visualize the dataset\n",
    "if X_train is not None and y_train is not None:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(X_train.numpy(), y_train.numpy(), alpha=0.5)\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Synthetic Dataset: y = 2x + 1 + noise')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(f\"Dataset created: X_train shape={X_train.shape}, y_train shape={y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the dataset into train (60%), validation (20%), and test (20%)\n",
    "# Use indices 0:60 for train, 60:80 for validation, 80:100 for test\n",
    "\n",
    "X_train_split = None  # First 60 samples\n",
    "y_train_split = None  # First 60 labels\n",
    "\n",
    "X_val = None  # Next 20 samples\n",
    "y_val = None  # Next 20 labels\n",
    "\n",
    "X_test = None  # Last 20 samples\n",
    "y_test = None  # Last 20 labels\n",
    "\n",
    "if X_train_split is not None:\n",
    "    print(f\"Train set: {len(X_train_split)} samples\")\n",
    "    print(f\"Validation set: {len(X_val)} samples\")\n",
    "    print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Section 1: Creating a Simple Dataset\n",
    "section_tests = [(getattr(validator, name), desc) for name, desc in EXERCISE1_SECTIONS[\"Section 1: Creating a Simple Dataset\"]]\n",
    "test_runner.test_section(\"Section 1: Creating a Simple Dataset\", validator, section_tests, locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: DataLoader with Different Batch Sizes\n",
    "\n",
    "DataLoaders are essential for:\n",
    "- Batching data for efficient training\n",
    "- Shuffling data between epochs\n",
    "- Parallel data loading\n",
    "\n",
    "Let's create DataLoaders with different batch sizes to see their effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a TensorDataset from the training split\n",
    "train_dataset = None\n",
    "\n",
    "if train_dataset is not None:\n",
    "    print(f\"TensorDataset created with {len(train_dataset)} samples\")\n",
    "    \n",
    "    # Check a sample\n",
    "    sample_x, sample_y = train_dataset[0]\n",
    "    print(f\"Sample input shape: {sample_x.shape}, Sample target shape: {sample_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create DataLoaders with different batch sizes\n",
    "# Create two DataLoaders: one with batch_size=8 and one with batch_size=16\n",
    "# Set shuffle=True for training\n",
    "\n",
    "train_loader_8 = None  # Batch size 8\n",
    "train_loader_16 = None  # Batch size 16\n",
    "\n",
    "if train_loader_8 is not None:\n",
    "    print(f\"DataLoader with batch size 8:\")\n",
    "    print(f\"  Number of batches: {len(train_loader_8)}\")\n",
    "    \n",
    "if train_loader_16 is not None:\n",
    "    print(f\"\\nDataLoader with batch size 16:\")\n",
    "    print(f\"  Number of batches: {len(train_loader_16)}\")\n",
    "    \n",
    "    # Show how batch size affects training\n",
    "    print(\"\\nBatch size comparison:\")\n",
    "    print(f\"  Batch size 8: {60/8:.1f} batches per epoch\")\n",
    "    print(f\"  Batch size 16: {60/16:.1f} batches per epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Section 2: DataLoader with Different Batch Sizes\n",
    "section_tests = [(getattr(validator, name), desc) for name, desc in EXERCISE1_SECTIONS[\"Section 2: DataLoader with Different Batch Sizes\"]]\n",
    "test_runner.test_section(\"Section 2: DataLoader with Different Batch Sizes\", validator, section_tests, locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Model and Loss Function\n",
    "\n",
    "For this simple regression task, we'll use:\n",
    "- A simple linear model (single linear layer)\n",
    "- Mean Squared Error (MSE) loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a simple linear model\n",
    "# The model should map from 1 input feature to 1 output\n",
    "# Use nn.Linear or create a simple custom model\n",
    "\n",
    "model = None\n",
    "\n",
    "if model is not None:\n",
    "    print(f\"Model created: {model}\")\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    test_input = torch.randn(1, 1)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"Test forward pass: input shape={test_input.shape}, output shape={test_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the loss function\n",
    "# Use Mean Squared Error (MSE) loss for regression\n",
    "\n",
    "loss_fn = None\n",
    "\n",
    "if loss_fn is not None:\n",
    "    print(f\"Loss function: {loss_fn}\")\n",
    "    \n",
    "    # Test loss computation\n",
    "    pred = torch.tensor([[1.0]])\n",
    "    target = torch.tensor([[2.0]])\n",
    "    test_loss = loss_fn(pred, target)\n",
    "    print(f\"Test MSE loss: pred={pred.item():.2f}, target={target.item():.2f}, loss={test_loss.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Section 3: Model and Loss Function\n",
    "section_tests = [(getattr(validator, name), desc) for name, desc in EXERCISE1_SECTIONS[\"Section 3: Model and Loss Function\"]]\n",
    "test_runner.test_section(\"Section 3: Model and Loss Function\", validator, section_tests, locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Optimizers\n",
    "\n",
    "Let's create two different optimizers to compare:\n",
    "- **SGD (Stochastic Gradient Descent)**: Simple, reliable, but can be slow\n",
    "- **Adam**: Adaptive learning rates, faster convergence, more complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh model for training\n",
    "if model is not None:\n",
    "    model = nn.Linear(1, 1)  # Reset model\n",
    "\n",
    "# TODO: Create SGD optimizer with learning rate 0.01\n",
    "optimizer_sgd = None\n",
    "\n",
    "# TODO: Create Adam optimizer with learning rate 0.001\n",
    "optimizer_adam = None\n",
    "\n",
    "if optimizer_sgd is not None:\n",
    "    print(f\"SGD optimizer created with lr=0.01\")\n",
    "    \n",
    "if optimizer_adam is not None:\n",
    "    print(f\"Adam optimizer created with lr=0.001\")\n",
    "    \n",
    "print(\"\\nOptimizer comparison:\")\n",
    "print(\"  SGD: Simple gradient descent, fixed learning rate\")\n",
    "print(\"  Adam: Adaptive moments, per-parameter learning rates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Section 4: Optimizers\n",
    "section_tests = [(getattr(validator, name), desc) for name, desc in EXERCISE1_SECTIONS[\"Section 4: Optimizers\"]]\n",
    "test_runner.test_section(\"Section 4: Optimizers\", validator, section_tests, locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Training Loop\n",
    "\n",
    "Now let's implement a complete training loop. The standard PyTorch training loop consists of:\n",
    "1. Forward pass: compute predictions\n",
    "2. Compute loss\n",
    "3. Backward pass: compute gradients\n",
    "4. Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a basic training loop\n",
    "# Train for 10 epochs using the SGD optimizer\n",
    "# Track the average loss for each epoch\n",
    "\n",
    "# Reset model and optimizer\n",
    "model = nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "train_losses = []  # Store average loss per epoch\n",
    "num_epochs = 10\n",
    "\n",
    "# TODO: Implement the training loop here\n",
    "# for epoch in range(num_epochs):\n",
    "#     epoch_loss = 0.0\n",
    "#     for batch_x, batch_y in train_loader_8:\n",
    "#         # 1. Zero gradients\n",
    "#         # 2. Forward pass\n",
    "#         # 3. Compute loss\n",
    "#         # 4. Backward pass\n",
    "#         # 5. Update weights\n",
    "#         # 6. Track loss\n",
    "#     # Calculate and store average epoch loss\n",
    "#     train_losses.append(average_loss)\n",
    "\n",
    "# Visualize training progress\n",
    "if train_losses:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Training Progress')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Initial loss: {train_losses[0]:.4f}\")\n",
    "    print(f\"Final loss: {train_losses[-1]:.4f}\")\n",
    "    print(f\"Loss reduction: {(1 - train_losses[-1]/train_losses[0]) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Section 5: Training Loop\n",
    "section_tests = [(getattr(validator, name), desc) for name, desc in EXERCISE1_SECTIONS[\"Section 5: Training Loop\"]]\n",
    "test_runner.test_section(\"Section 5: Training Loop\", validator, section_tests, locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Evaluation on Train/Val/Test\n",
    "\n",
    "It's crucial to evaluate your model on different data splits:\n",
    "- **Training set**: How well the model fits the training data\n",
    "- **Validation set**: How well the model generalizes (used for hyperparameter tuning)\n",
    "- **Test set**: Final evaluation (only used once at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an evaluation function\n",
    "def evaluate_model(model, dataloader, loss_fn):\n",
    "    \"\"\"\n",
    "    Evaluate model on a dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        dataloader: DataLoader for the evaluation data\n",
    "        loss_fn: Loss function to use\n",
    "    \n",
    "    Returns:\n",
    "        Average loss over the dataset\n",
    "    \"\"\"\n",
    "    # TODO: Implement evaluation\n",
    "    # 1. Set model to eval mode\n",
    "    # 2. Disable gradient computation\n",
    "    # 3. Iterate through dataloader\n",
    "    # 4. Compute predictions and loss\n",
    "    # 5. Return average loss\n",
    "    \n",
    "    return None  # Return average loss\n",
    "\n",
    "# Test the function\n",
    "if evaluate_model(model, train_loader_8, loss_fn) is not None:\n",
    "    print(\"Evaluation function implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train with train/validation monitoring\n",
    "# Train for 20 epochs and track both training and validation losses\n",
    "\n",
    "# Create fresh model and data loaders\n",
    "model = nn.Linear(1, 1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create validation dataloader\n",
    "val_dataset = TensorDataset(X_val, y_val) if X_val is not None else None\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False) if val_dataset else None\n",
    "\n",
    "final_train_losses = []\n",
    "final_val_losses = []\n",
    "num_epochs = 20\n",
    "\n",
    "# TODO: Implement training with validation monitoring\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Training phase\n",
    "#     model.train()\n",
    "#     # ... training loop ...\n",
    "#     \n",
    "#     # Evaluation phase\n",
    "#     train_loss = evaluate_model(model, train_loader_8, loss_fn)\n",
    "#     val_loss = evaluate_model(model, val_loader, loss_fn)\n",
    "#     \n",
    "#     final_train_losses.append(train_loss)\n",
    "#     final_val_losses.append(val_loss)\n",
    "\n",
    "# Visualize train vs validation losses\n",
    "if final_train_losses and final_val_losses:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(final_train_losses, label='Train Loss', marker='o')\n",
    "    plt.plot(final_val_losses, label='Validation Loss', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Final training loss: {final_train_losses[-1]:.4f}\")\n",
    "    print(f\"Final validation loss: {final_val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# Create test dataloader and evaluate the final model\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test) if X_test is not None else None\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False) if test_dataset else None\n",
    "\n",
    "test_loss = None  # TODO: Evaluate model on test set\n",
    "\n",
    "if test_loss is not None:\n",
    "    print(f\"Test set loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Compare all three\n",
    "    if final_train_losses and final_val_losses:\n",
    "        print(\"\\nFinal comparison:\")\n",
    "        print(f\"  Train loss: {final_train_losses[-1]:.4f}\")\n",
    "        print(f\"  Val loss: {final_val_losses[-1]:.4f}\")\n",
    "        print(f\"  Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Section 6: Evaluation on Train/Val/Test\n",
    "section_tests = [(getattr(validator, name), desc) for name, desc in EXERCISE1_SECTIONS[\"Section 6: Evaluation on Train/Val/Test\"]]\n",
    "test_runner.test_section(\"Section 6: Evaluation on Train/Val/Test\", validator, section_tests, locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Learning Rate Comparison\n",
    "\n",
    "The learning rate is one of the most important hyperparameters. Let's compare different learning rates to see their effect on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare different learning rates\n",
    "# Train models with learning rates: 0.0001, 0.001, 0.01, 0.1\n",
    "# Track losses for each learning rate\n",
    "\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "lr_results = {}  # Dictionary to store results for each learning rate\n",
    "\n",
    "# TODO: For each learning rate:\n",
    "# 1. Create a fresh model\n",
    "# 2. Create optimizer with that learning rate\n",
    "# 3. Train for a few epochs (e.g., 10)\n",
    "# 4. Store the loss history\n",
    "\n",
    "# for lr in learning_rates:\n",
    "#     model = nn.Linear(1, 1)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "#     losses = []\n",
    "#     \n",
    "#     # Training loop...\n",
    "#     \n",
    "#     lr_results[lr] = losses\n",
    "\n",
    "# Visualize learning rate comparison\n",
    "if lr_results:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for lr, losses in lr_results.items():\n",
    "        plt.plot(losses, label=f'LR={lr}', marker='o')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Rate Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.yscale('log')  # Log scale for better visualization\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Learning rate analysis:\")\n",
    "    for lr in learning_rates:\n",
    "        if lr in lr_results and lr_results[lr]:\n",
    "            initial = lr_results[lr][0]\n",
    "            final = lr_results[lr][-1]\n",
    "            print(f\"  LR={lr}: Initial loss={initial:.4f}, Final loss={final:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Section 7: Learning Rate Comparison\n",
    "section_tests = [(getattr(validator, name), desc) for name, desc in EXERCISE1_SECTIONS[\"Section 7: Learning Rate Comparison\"]]\n",
    "test_runner.test_section(\"Section 7: Learning Rate Comparison\", validator, section_tests, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final summary of all tests\n",
    "test_runner.final_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
