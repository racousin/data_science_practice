{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3167342-383d-4c7a-b9a0-919c6fd662cc",
   "metadata": {},
   "source": [
    "# Math Problem Solving with Transformers: From Pre-trained Models to Fine-tuning\n",
    "\n",
    "This notebook provides a complete walkthrough of using transformers for math problem solving, covering:\n",
    "1. Problem setup and dataset generation\n",
    "2. Using pre-trained transformer models\n",
    "3. Zero-shot learning with small LLMs\n",
    "4. Fine-tuning with LoRA\n",
    "\n",
    "## 1. Problem Setup and Data Generation\n",
    "\n",
    "First, let's import necessary libraries and set up our environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4029af0f-3ae3-4984-bb27-900174fe846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import re\n",
    "\n",
    "# For transformer models\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM,\n",
    "    T5ForConditionalGeneration, GPT2LMHeadModel, \n",
    "    Trainer, TrainingArguments,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "# For fine-tuning\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374bd303-2770-4e14-9f3e-3fdd40085249",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1.1 Generate Math Problem Dataset\n",
    "\n",
    "Let's create a simple but versatile math problem generator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b81940-06b9-4158-a585-4f3953b5eb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3000 problems\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>solution</th>\n",
       "      <th>work</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 - 1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>To solve 4 - 1, I subtract 1 from 4 to get 3.</td>\n",
       "      <td>easy</td>\n",
       "      <td>0</td>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25 + 24</td>\n",
       "      <td>49.0</td>\n",
       "      <td>To solve 25 + 24, I add 25 and 24 to get 49.</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 + 18</td>\n",
       "      <td>41.0</td>\n",
       "      <td>To solve 23 + 18, I add 23 and 18 to get 41.</td>\n",
       "      <td>hard</td>\n",
       "      <td>2</td>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19 + 14</td>\n",
       "      <td>33.0</td>\n",
       "      <td>To solve 19 + 14, I add 19 and 14 to get 33.</td>\n",
       "      <td>easy</td>\n",
       "      <td>3</td>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 + 15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>To solve 11 + 15, I add 11 and 15 to get 26.</td>\n",
       "      <td>medium</td>\n",
       "      <td>4</td>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem  solution                                           work  \\\n",
       "0    4 - 1       3.0  To solve 4 - 1, I subtract 1 from 4 to get 3.   \n",
       "1  25 + 24      49.0   To solve 25 + 24, I add 25 and 24 to get 49.   \n",
       "2  23 + 18      41.0   To solve 23 + 18, I add 23 and 18 to get 41.   \n",
       "3  19 + 14      33.0   To solve 19 + 14, I add 19 and 14 to get 33.   \n",
       "4  11 + 15      26.0   To solve 11 + 15, I add 11 and 15 to get 26.   \n",
       "\n",
       "  difficulty  id     type  \n",
       "0       easy   0  numeric  \n",
       "1     medium   1  numeric  \n",
       "2       hard   2  numeric  \n",
       "3       easy   3  numeric  \n",
       "4     medium   4  numeric  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def generate_math_problem(difficulty='easy'):\n",
    "    \"\"\"Generate a simple math problem based on difficulty level.\"\"\"\n",
    "    if difficulty == 'easy':\n",
    "        a, b = random.randint(1, 20), random.randint(1, 20)\n",
    "        operation = random.choice(['+', '-'])\n",
    "    elif difficulty == 'medium':\n",
    "        a, b = random.randint(10, 50), random.randint(10, 50)\n",
    "        operation = random.choice(['+', '-', '*'])\n",
    "    else:  # 'hard'\n",
    "        a, b = random.randint(10, 100), random.randint(1, 20)\n",
    "        operation = random.choice(['+', '-', '*', '/'])\n",
    "        if operation == '/':  # Ensure clean division\n",
    "            a = b * random.randint(1, 10)\n",
    "    \n",
    "    problem = f\"{a} {operation} {b}\"\n",
    "    \n",
    "    # Calculate solution\n",
    "    if operation == '+':\n",
    "        solution = a + b\n",
    "        work = f\"To solve {a} + {b}, I add {a} and {b} to get {solution}.\"\n",
    "    elif operation == '-':\n",
    "        solution = a - b\n",
    "        work = f\"To solve {a} - {b}, I subtract {b} from {a} to get {solution}.\"\n",
    "    elif operation == '*':\n",
    "        solution = a * b\n",
    "        work = f\"To solve {a} * {b}, I multiply {a} by {b} to get {solution}.\"\n",
    "    elif operation == '/':\n",
    "        solution = a // b  # Integer division\n",
    "        work = f\"To solve {a} / {b}, I divide {a} by {b} to get {solution}.\"\n",
    "    \n",
    "    return {\n",
    "        'problem': problem,\n",
    "        'solution': solution,\n",
    "        'work': work,\n",
    "        'difficulty': difficulty\n",
    "    }\n",
    "\n",
    "def generate_word_problem(difficulty='easy'):\n",
    "    \"\"\"Generate a word problem based on difficulty.\"\"\"\n",
    "    templates = {\n",
    "        'easy': [\n",
    "            \"John has {a} apples and gets {b} more. How many apples does John have now?\",\n",
    "            \"Sarah has {a} dollars and spends {b} dollars. How much money does she have left?\",\n",
    "            \"There are {a} students in the class and {b} more join. How many students are there now?\"\n",
    "        ],\n",
    "        'medium': [\n",
    "            \"A store sold {a} items on Monday and {b} items on Tuesday. How many items were sold in total?\",\n",
    "            \"A book costs ${a} and a notebook costs ${b}. How much do 2 books and 3 notebooks cost in total?\",\n",
    "            \"A train travels at {a} miles per hour for {b} hours. How far does it travel?\"\n",
    "        ],\n",
    "        'hard': [\n",
    "            \"If {a} workers can complete a job in {b} days, how many days would it take {c} workers to complete the same job?\",\n",
    "            \"A store has a {a}% discount on all items. If an item originally costs ${b}, what is the sale price?\",\n",
    "            \"A car uses {a} gallons of gas to travel {b} miles. At this rate, how many gallons will it use to travel {c} miles?\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    template = random.choice(templates[difficulty])\n",
    "    \n",
    "    if difficulty == 'easy':\n",
    "        a = random.randint(5, 20)\n",
    "        b = random.randint(1, 10)\n",
    "        \n",
    "        if \"more\" in template or \"join\" in template:\n",
    "            solution = a + b\n",
    "            work = f\"To solve this problem, I need to add {a} and {b}, which gives me {solution}.\"\n",
    "        elif \"spends\" in template:\n",
    "            solution = a - b\n",
    "            work = f\"To solve this problem, I need to subtract {b} from {a}, which gives me {solution}.\"\n",
    "        \n",
    "        problem = template.format(a=a, b=b)\n",
    "        \n",
    "    elif difficulty == 'medium':\n",
    "        a = random.randint(10, 50)\n",
    "        b = random.randint(10, 50)\n",
    "        \n",
    "        if \"total\" in template and \"2 books\" not in template:\n",
    "            solution = a + b\n",
    "            work = f\"To solve this problem, I need to add {a} and {b}, which gives me {solution}.\"\n",
    "        elif \"2 books\" in template:\n",
    "            solution = 2*a + 3*b\n",
    "            work = f\"To solve this problem, I need to calculate 2*{a} + 3*{b} = {2*a} + {3*b} = {solution}.\"\n",
    "        elif \"train\" in template:\n",
    "            solution = a * b\n",
    "            work = f\"To solve this problem, I need to multiply the speed ({a} mph) by the time ({b} hours), which gives me {solution} miles.\"\n",
    "            \n",
    "        problem = template.format(a=a, b=b)\n",
    "        \n",
    "    else:  # 'hard'\n",
    "        a = random.randint(5, 20)\n",
    "        b = random.randint(10, 30)\n",
    "        c = random.randint(5, 15)\n",
    "        \n",
    "        if \"workers\" in template:\n",
    "            solution = (a * b) // c  # Integer division\n",
    "            work = f\"To solve this problem, I need to use the formula: (workers1 * days1) = (workers2 * days2). So ({a} * {b}) = ({c} * days2). This gives me days2 = ({a} * {b}) / {c} = {solution}.\"\n",
    "        elif \"discount\" in template:\n",
    "            discounted_price = b * (100 - a) / 100\n",
    "            solution = discounted_price\n",
    "            work = f\"To solve this problem, I need to calculate the discounted price as original price * (100% - discount%). So ${b} * (100% - {a}%) = ${b} * {100-a}% = ${solution}.\"\n",
    "        elif \"car\" in template:\n",
    "            gallons_per_mile = a / b\n",
    "            solution = gallons_per_mile * c\n",
    "            work = f\"To solve this problem, I need to find the rate in gallons per mile: {a} gallons / {b} miles = {a/b} gallons per mile. Then I multiply by {c} miles to get {solution} gallons.\"\n",
    "            \n",
    "        problem = template.format(a=a, b=b, c=c)\n",
    "    \n",
    "    return {\n",
    "        'problem': problem,\n",
    "        'solution': float(solution),  # Convert to float for decimal solutions\n",
    "        'work': work,\n",
    "        'difficulty': difficulty,\n",
    "        'type': 'word'\n",
    "    }\n",
    "\n",
    "def generate_dataset(n_samples=1000):\n",
    "    \"\"\"Generate a dataset of math problems with an equal mix of types and difficulties.\"\"\"\n",
    "    data = []\n",
    "    difficulties = ['easy', 'medium', 'hard']\n",
    "    \n",
    "    # Generate numeric problems\n",
    "    for i in range(n_samples // 2):\n",
    "        difficulty = difficulties[i % 3]\n",
    "        problem_data = generate_math_problem(difficulty)\n",
    "        problem_data['id'] = i\n",
    "        problem_data['type'] = 'numeric'\n",
    "        data.append(problem_data)\n",
    "    \n",
    "    # Generate word problems\n",
    "    for i in range(n_samples // 2, n_samples):\n",
    "        difficulty = difficulties[i % 3]\n",
    "        problem_data = generate_word_problem(difficulty)\n",
    "        problem_data['id'] = i\n",
    "        data.append(problem_data)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate our dataset\n",
    "df = generate_dataset(n_samples=3000)\n",
    "print(f\"Generated {len(df)} problems\")\n",
    "\n",
    "# Display the first few examples\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef745ae3-0e1d-4dbc-b0f2-e39197733793",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 Data Analysis and Preprocessing\n",
    "\n",
    "Let's explore our dataset and prepare it for modeling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c575ca-565a-453d-bf64-94603dc27176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem types: {'numeric': 1500, 'word': 1500}\n",
      "Difficulty levels: {'easy': 1000, 'medium': 1000, 'hard': 1000}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 2400 examples\n",
      "Validation set: 300 examples\n",
      "Test set: 300 examples\n",
      "Sequence-to-Sequence format example:\n",
      "{'input': 'Solve: A book costs $42 and a notebook costs $31. How much do 2 books and 3 notebooks cost in total?', 'output': '177.0'}\n",
      "\n",
      "Causal format example:\n",
      "{'text': 'Problem: A book costs $42 and a notebook costs $31. How much do 2 books and 3 notebooks cost in total?\\nSolution: The answer is 177.0.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Basic statistics\n",
    "print(f\"Problem types: {df['type'].value_counts().to_dict()}\")\n",
    "print(f\"Difficulty levels: {df['difficulty'].value_counts().to_dict()}\")\n",
    "\n",
    "# Plot distribution of problem types and difficulties\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.countplot(data=df, x='type', ax=ax1)\n",
    "ax1.set_title('Distribution of Problem Types')\n",
    "sns.countplot(data=df, x='difficulty', ax=ax2)\n",
    "ax2.set_title('Distribution of Difficulty Levels')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create train/validation/test splits\n",
    "train_df = df.sample(frac=0.8, random_state=RANDOM_SEED)\n",
    "temp_df = df.drop(train_df.index)\n",
    "val_df = temp_df.sample(frac=0.5, random_state=RANDOM_SEED)\n",
    "test_df = temp_df.drop(val_df.index)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} examples\")\n",
    "print(f\"Validation set: {len(val_df)} examples\")\n",
    "print(f\"Test set: {len(test_df)} examples\")\n",
    "\n",
    "# Function to format the problems for different model types\n",
    "def format_for_seq2seq(problem_data, include_work=False):\n",
    "    \"\"\"Format a problem for sequence-to-sequence models like T5.\"\"\"\n",
    "    input_text = f\"Solve: {problem_data['problem']}\"\n",
    "    if include_work:\n",
    "        output_text = f\"{problem_data['work']} The answer is {problem_data['solution']}.\"\n",
    "    else:\n",
    "        output_text = f\"{problem_data['solution']}\"\n",
    "    return {\"input\": input_text, \"output\": output_text}\n",
    "\n",
    "def format_for_causal(problem_data, include_work=False):\n",
    "    \"\"\"Format a problem for causal language models like GPT.\"\"\"\n",
    "    if include_work:\n",
    "        text = f\"Problem: {problem_data['problem']}\\nSolution: {problem_data['work']} The answer is {problem_data['solution']}.\"\n",
    "    else:\n",
    "        text = f\"Problem: {problem_data['problem']}\\nSolution: The answer is {problem_data['solution']}.\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "# Format datasets for different model types\n",
    "train_seq2seq = [format_for_seq2seq(row) for _, row in train_df.iterrows()]\n",
    "val_seq2seq = [format_for_seq2seq(row) for _, row in val_df.iterrows()]\n",
    "test_seq2seq = [format_for_seq2seq(row) for _, row in test_df.iterrows()]\n",
    "\n",
    "train_causal = [format_for_causal(row) for _, row in train_df.iterrows()]\n",
    "val_causal = [format_for_causal(row) for _, row in val_df.iterrows()]\n",
    "test_causal = [format_for_causal(row) for _, row in test_df.iterrows()]\n",
    "\n",
    "# Convert to HuggingFace datasets for easier use with their Trainer\n",
    "train_hf_seq2seq = HFDataset.from_list(train_seq2seq)\n",
    "val_hf_seq2seq = HFDataset.from_list(val_seq2seq)\n",
    "test_hf_seq2seq = HFDataset.from_list(test_seq2seq)\n",
    "\n",
    "train_hf_causal = HFDataset.from_list(train_causal)\n",
    "val_hf_causal = HFDataset.from_list(val_causal)\n",
    "test_hf_causal = HFDataset.from_list(test_causal)\n",
    "\n",
    "# Display a few examples in both formats\n",
    "print(\"Sequence-to-Sequence format example:\")\n",
    "print(train_seq2seq[0])\n",
    "print(\"\\nCausal format example:\")\n",
    "print(train_causal[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e6e8e-6652-4b63-a345-212ceb2f43ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1.3 Evaluation Functions\n",
    "\n",
    "Let's define functions to evaluate model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bea992b-d7d4-45dc-9994-5a4a8b43cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_answer(text):\n",
    "    \"\"\"Extract the numerical answer from model output.\"\"\"\n",
    "    # Try to find \"the answer is X\" pattern\n",
    "    match = re.search(r\"the answer is ([-+]?\\d*\\.?\\d+)\", text.lower())\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # Try to find just a number at the end of the text\n",
    "    match = re.search(r\"([-+]?\\d*\\.?\\d+)\\.?$\", text.strip())\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # Try to find any number in the text\n",
    "    match = re.search(r\"([-+]?\\d*\\.?\\d+)\", text)\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "def evaluate_model_predictions(predictions, references):\n",
    "    \"\"\"Evaluate model predictions against references.\"\"\"\n",
    "    correct = 0\n",
    "    extracted = 0\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        extracted_answer = extract_answer(pred)\n",
    "        if extracted_answer is not None:\n",
    "            extracted += 1\n",
    "            if abs(extracted_answer - ref) < 1e-5:  # Allow for floating point error\n",
    "                correct += 1\n",
    "    \n",
    "    accuracy = correct / len(references) if len(references) > 0 else 0\n",
    "    extraction_rate = extracted / len(references) if len(references) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"extraction_rate\": extraction_rate,\n",
    "        \"extracted_correct\": correct,\n",
    "        \"total\": len(references)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4835cf9-de4b-4f39-aa4a-cb4a0c637f64",
   "metadata": {},
   "source": [
    "## 2. train Transformer Models from scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6fd2a2-191d-4d48-8aac-cbfe8f92c08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.bert.modeling_bert.BertModel'> is overwritten by shared encoder config: BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.bert.modeling_bert.BertLMHeadModel'> is overwritten by shared decoder config: BertConfig {\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5f3df54c844e1ebeb7d68af8a87910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff8355b31e641dc9907f72030801dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419e0f8fe8d649a1a22472f4520d07ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphael/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BertModel.forward() got an unexpected keyword argument 'num_items_in_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 125\u001b[0m\n\u001b[1;32m    116\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    117\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    118\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Evaluate on test set\u001b[39;00m\n\u001b[1;32m    128\u001b[0m test_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_test)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3704\u001b[0m ):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/trainer.py:3759\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3757\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3758\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:603\u001b[0m, in \u001b[0;36mEncoderDecoderModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m kwargs_decoder \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    599\u001b[0m     argument[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_\u001b[39m\u001b[38;5;124m\"\u001b[39m) :]: value \u001b[38;5;28;01mfor\u001b[39;00m argument, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m argument\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    600\u001b[0m }\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 603\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    613\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\u001b[38;5;241m*\u001b[39mencoder_outputs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: BertModel.forward() got an unexpected keyword argument 'num_items_in_batch'"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EncoderDecoderModel,\n",
    "    EncoderDecoderConfig,\n",
    "    BertConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "\n",
    "# Create tokenizer (just for vocabulary - not using pre-trained weights)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Create encoder config (from scratch)\n",
    "encoder_config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    ")\n",
    "\n",
    "# Create decoder config (from scratch)\n",
    "decoder_config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    "    is_decoder=True,\n",
    "    add_cross_attention=True,\n",
    ")\n",
    "\n",
    "# Create encoder-decoder config\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(encoder_config, decoder_config)\n",
    "\n",
    "# Create the model with random weights (no pre-training)\n",
    "model = EncoderDecoderModel(config=config)\n",
    "model.to(device)\n",
    "\n",
    "# Tokenization function for sequence-to-sequence models\n",
    "def tokenize_seq2seq(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"input\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    outputs = tokenizer(\n",
    "        examples[\"output\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Set the decoder_input_ids to match the expected format\n",
    "    # We need to shift the labels to ensure proper teacher forcing\n",
    "    batch = {\n",
    "        \"input_ids\": inputs.input_ids,\n",
    "        \"attention_mask\": inputs.attention_mask,\n",
    "        \"decoder_input_ids\": outputs.input_ids,\n",
    "        \"decoder_attention_mask\": outputs.attention_mask,\n",
    "        \"labels\": outputs.input_ids.clone(),\n",
    "    }\n",
    "    \n",
    "    # Set padding tokens in labels to -100 so they're ignored in the loss\n",
    "    batch[\"labels\"][batch[\"labels\"] == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Tokenize our datasets\n",
    "tokenized_train = train_hf_seq2seq.map(tokenize_seq2seq, batched=True)\n",
    "tokenized_val = val_hf_seq2seq.map(tokenize_seq2seq, batched=True)\n",
    "tokenized_test = test_hf_seq2seq.map(tokenize_seq2seq, batched=True)\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=\"none\",  # Disable wandb/tensorboard if you don't need them\n",
    ")\n",
    "\n",
    "# Define a compute_metrics function if needed\n",
    "def compute_metrics(pred):\n",
    "    return {\"loss\": pred.loss}\n",
    "\n",
    "# Set up trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = trainer.evaluate(tokenized_test)\n",
    "print(f\"Test Loss: {test_results['eval_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eca7a9-47e5-4710-9af2-621bcc858982",
   "metadata": {},
   "source": [
    "## 3. Zero-Shot Learning with Small LLMs\n",
    "\n",
    "Now let's try using a small LLM for zero-shot prediction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3077adb5-0dad-4003-bada-b489f30cea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c977c11114a94f51b9d6d73ac0e289c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b48db134124f7199f04c72c3cb8bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b340a6fdc0324d6f9f0512ded5bca70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Zero-shot evaluation:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot LLM Results:\n",
      "Accuracy: 0.0033\n",
      "Answer extraction rate: 0.8967\n",
      "Correct answers: 1 out of 300\n",
      "  Easy problems: 0.0000\n",
      "  Medium problems: 0.0000\n",
      "  Hard problems: 0.0000\n",
      "  Numeric problems: 0.0000\n",
      "  Word problems: 0.0000\n",
      "\n",
      "Example Zero-Shot Predictions:\n",
      "Problem: 11 + 15\n",
      "True solution: 26.0\n",
      "Predicted:  Add a new function to the function definition.\n",
      "\n",
      "Files: src/eval.c, src/testdir/test_eval.vim, src/testdir/test_eval.vim\n",
      "\n",
      "Patch 8.0.0\n",
      "\n",
      "\n",
      "\n",
      "Problem: 16 - 34\n",
      "True solution: -18.0\n",
      "Predicted:  Add a new line to the end of the file.\n",
      "\n",
      "Files: src/testdir/test_python.vim Patch 7.0.0\n",
      "\n",
      "Problem: Cannot find the file name of the file.\n",
      "\n",
      "Solution: Add a\n",
      "\n",
      "Problem: 2 + 4\n",
      "True solution: 6.0\n",
      "Predicted:  Add a new function to the function definition.\n",
      "\n",
      "Files: src/eval.c, src/testdir/test_eval.vim, src/testdir/test_eval.vim\n",
      "\n",
      "Patch 8.0.0\n",
      "\n",
      "\n",
      "\n",
      "Problem: 24 + 14\n",
      "True solution: 38.0\n",
      "Predicted:  Add a new line to the end of the file.\n",
      "\n",
      "Files: src/testdir/test_python.vim Patch 7.0.0\n",
      "\n",
      "Problem: Cannot find the file name of a file.\n",
      "\n",
      "Solution: Add a\n",
      "\n",
      "Problem: 7 - 7\n",
      "True solution: 0.0\n",
      "Predicted:  Add a new line to the end of the file.\n",
      "\n",
      "Files: src/testdir/test_python.vim Patch 7.0.0\n",
      "\n",
      "Problem: Cannot find the file name of a file.\n",
      "\n",
      "Solution: Add a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We'll use GPT-2 Small as our \"small LLM\"\n",
    "llm_model_name = \"gpt2\"  # You can try other small LLMs like \"distilgpt2\" or \"EleutherAI/gpt-neo-125M\"\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name)\n",
    "llm_model.to(device)\n",
    "\n",
    "# Add padding token if it doesn't exist\n",
    "if llm_tokenizer.pad_token is None:\n",
    "    llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
    "\n",
    "# Function to generate zero-shot predictions\n",
    "def zero_shot_generate(problem, max_new_tokens=50):\n",
    "    prompt = f\"Problem: {problem}\\nSolution:\"\n",
    "    input_ids = llm_tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = llm_model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=llm_tokenizer.pad_token_id,\n",
    "            do_sample=False  # Use greedy decoding for more predictable outputs\n",
    "        )\n",
    "    \n",
    "    generated_text = llm_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    # Extract just the solution part (after the prompt)\n",
    "    solution_text = generated_text[len(prompt):]\n",
    "    return solution_text\n",
    "\n",
    "# Evaluate the LLM in zero-shot mode\n",
    "def evaluate_zero_shot():\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for i in tqdm(range(len(test_df)), desc=\"Zero-shot evaluation\"):\n",
    "        problem = test_df.iloc[i]['problem']\n",
    "        prediction = zero_shot_generate(problem)\n",
    "        predictions.append(prediction)\n",
    "        references.append(float(test_df.iloc[i]['solution']))\n",
    "    \n",
    "    results = evaluate_model_predictions(predictions, references)\n",
    "    print(f\"Zero-Shot LLM Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Answer extraction rate: {results['extraction_rate']:.4f}\")\n",
    "    print(f\"Correct answers: {results['extracted_correct']} out of {results['total']}\")\n",
    "    \n",
    "    # Analyze by difficulty\n",
    "    for difficulty in ['easy', 'medium', 'hard']:\n",
    "        indices = test_df[test_df['difficulty'] == difficulty].index\n",
    "        diff_predictions = [predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        diff_references = [references[i] for i in range(len(test_df)) if i in indices]\n",
    "        diff_results = evaluate_model_predictions(diff_predictions, diff_references)\n",
    "        print(f\"  {difficulty.capitalize()} problems: {diff_results['accuracy']:.4f}\")\n",
    "    \n",
    "    # Analyze by type\n",
    "    for problem_type in ['numeric', 'word']:\n",
    "        indices = test_df[test_df['type'] == problem_type].index\n",
    "        type_predictions = [predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        type_references = [references[i] for i in range(len(test_df)) if i in indices]\n",
    "        type_results = evaluate_model_predictions(type_predictions, type_references)\n",
    "        print(f\"  {problem_type.capitalize()} problems: {type_results['accuracy']:.4f}\")\n",
    "    \n",
    "    return predictions, references, results\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "zs_predictions, zs_references, zs_results = evaluate_zero_shot()\n",
    "\n",
    "# Look at some example predictions\n",
    "print(\"\\nExample Zero-Shot Predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"Problem: {test_df.iloc[i]['problem']}\")\n",
    "    print(f\"True solution: {test_df.iloc[i]['solution']}\")\n",
    "    print(f\"Predicted: {zs_predictions[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c915d97-4a31-4aec-9ace-a467978f4893",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning with LoRA\n",
    "\n",
    "Finally, let's fine-tune our LLM using LoRA for efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a90c67-9861-43c0-84e7-4cbd580f2fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ft_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# You can use gpt2 if GPU memory is limited\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ft_tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(ft_model_name)\n\u001b[0;32m----> 4\u001b[0m ft_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mft_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use 8-bit quantization for memory efficiency\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Add padding token if it doesn't exist\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ft_tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:262\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:3698\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3698\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3705\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[1;32m   3706\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-science-practice-izly4xBC-py3.12/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:73\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_bitsandbytes_available():\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_bnb_backend_availability\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n",
      "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`"
     ]
    }
   ],
   "source": [
    "# Use a slightly larger model for fine-tuning if possible\n",
    "ft_model_name = \"gpt2\"  # You can use gpt2 if GPU memory is limited\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(ft_model_name)\n",
    "ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    ft_model_name,\n",
    "    load_in_8bit=True,  # Use 8-bit quantization for memory efficiency\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Add padding token if it doesn't exist\n",
    "if ft_tokenizer.pad_token is None:\n",
    "    ft_tokenizer.pad_token = ft_tokenizer.eos_token\n",
    "\n",
    "# Prepare the model for fine-tuning\n",
    "ft_model = prepare_model_for_kbit_training(ft_model)\n",
    "\n",
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],  # Layers to apply LoRA\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "ft_model = get_peft_model(ft_model, lora_config)\n",
    "print(f\"Trainable parameters: {ft_model.print_trainable_parameters()}\")\n",
    "\n",
    "# Prepare training data - we'll format it for causal LMs\n",
    "def tokenize_causal_lm(examples):\n",
    "    # Format the examples for causal LM\n",
    "    texts = []\n",
    "    for i in range(len(examples[\"text\"])):\n",
    "        texts.append(examples[\"text\"][i])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized = ft_tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Prepare labels (same as input_ids for causal LM)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train_causal = train_hf_causal.map(tokenize_causal_lm, batched=True)\n",
    "tokenized_val_causal = val_hf_causal.map(tokenize_causal_lm, batched=True)\n",
    "\n",
    "# Training arguments\n",
    "ft_training_args = TrainingArguments(\n",
    "    output_dir=\"./results-lora\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs-lora\",\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    fp16=True,  # Mixed precision training\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "ft_trainer = Trainer(\n",
    "    model=ft_model,\n",
    "    args=ft_training_args,\n",
    "    train_dataset=tokenized_train_causal,\n",
    "    eval_dataset=tokenized_val_causal,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "ft_trainer.train()\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "def evaluate_ft_model():\n",
    "    ft_model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for i in tqdm(range(len(test_df)), desc=\"Fine-tuned model evaluation\"):\n",
    "        problem = test_df.iloc[i]['problem']\n",
    "        prompt = f\"Problem: {problem}\\nSolution:\"\n",
    "        input_ids = ft_tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = ft_model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=50,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=ft_tokenizer.pad_token_id,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        generated_text = ft_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        # Extract just the solution part\n",
    "        solution_text = generated_text[len(prompt):]\n",
    "        predictions.append(solution_text)\n",
    "        references.append(float(test_df.iloc[i]['solution']))\n",
    "    \n",
    "    results = evaluate_model_predictions(predictions, references)\n",
    "    print(f\"Fine-tuned Model Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Answer extraction rate: {results['extraction_rate']:.4f}\")\n",
    "    print(f\"Correct answers: {results['extracted_correct']} out of {results['total']}\")\n",
    "    \n",
    "    # Analyze by difficulty\n",
    "    for difficulty in ['easy', 'medium', 'hard']:\n",
    "        indices = test_df[test_df['difficulty'] == difficulty].index\n",
    "        diff_predictions = [predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        diff_references = [references[i] for i in range(len(test_df)) if i in indices]\n",
    "        diff_results = evaluate_model_predictions(diff_predictions, diff_references)\n",
    "        print(f\"  {difficulty.capitalize()} problems: {diff_results['accuracy']:.4f}\")\n",
    "    \n",
    "    # Analyze by type\n",
    "    for problem_type in ['numeric', 'word']:\n",
    "        indices = test_df[test_df['type'] == problem_type].index\n",
    "        type_predictions = [predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        type_references = [references[i] for i in range(len(test_df)) if i in indices]\n",
    "        type_results = evaluate_model_predictions(type_predictions, type_references)\n",
    "        print(f\"  {problem_type.capitalize()} problems: {type_results['accuracy']:.4f}\")\n",
    "    \n",
    "    return predictions, references, results\n",
    "\n",
    "# Run evaluation\n",
    "ft_predictions, ft_references, ft_results = evaluate_ft_model()\n",
    "\n",
    "# Look at some example predictions\n",
    "print(\"\\nExample Fine-tuned Model Predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"Problem: {test_df.iloc[i]['problem']}\")\n",
    "    print(f\"True solution: {test_df.iloc[i]['solution']}\")\n",
    "    print(f\"Predicted: {ft_predictions[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781785c1-0f0f-4423-8738-0dca2b849d15",
   "metadata": {},
   "source": [
    "## 5. Comparison and Analysis\n",
    "Let's compare the three approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115da2a-7d15-48ca-81f7-0e6aa5485622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table\n",
    "results = {\n",
    "    \"T5 Pre-trained\": t5_results,\n",
    "    \"Zero-Shot GPT-2\": zs_results,\n",
    "    \"Fine-tuned GPT-2\": ft_results\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": list(results.keys()),\n",
    "    \"Accuracy\": [r[\"accuracy\"] for r in results.values()],\n",
    "    \"Extraction Rate\": [r[\"extraction_rate\"] for r in results.values()],\n",
    "    \"Correct/Total\": [f\"{r['extracted_correct']}/{r['total']}\" for r in results.values()]\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = comparison_df[\"Model\"]\n",
    "y = comparison_df[\"Accuracy\"]\n",
    "plt.bar(x, y, color=['blue', 'green', 'orange'])\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "for i, v in enumerate(y):\n",
    "    plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize performance by difficulty\n",
    "difficulty_data = {model_name: {} for model_name in results.keys()}\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    # Collect results for each difficulty level\n",
    "    for difficulty in ['easy', 'medium', 'hard']:\n",
    "        indices = test_df[test_df['difficulty'] == difficulty].index\n",
    "        if model_name == \"T5 Pre-trained\":\n",
    "            diff_predictions = [t5_predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        elif model_name == \"Zero-Shot GPT-2\":\n",
    "            diff_predictions = [zs_predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        else:\n",
    "            diff_predictions = [ft_predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        \n",
    "        diff_references = [test_df.iloc[i]['solution'] for i in range(len(test_df)) if i in indices]\n",
    "        diff_results = evaluate_model_predictions(diff_predictions, diff_references)\n",
    "        difficulty_data[model_name][difficulty] = diff_results['accuracy']\n",
    "\n",
    "# Create a grouped bar chart for difficulty comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(difficulty_data[list(difficulty_data.keys())[0]]))\n",
    "width = 0.25\n",
    "multiplier = 0\n",
    "\n",
    "for model_name, difficulties in difficulty_data.items():\n",
    "    offset = width * multiplier\n",
    "    plt.bar(x + offset, list(difficulties.values()), width, label=model_name)\n",
    "    multiplier += 1\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance by Problem Difficulty')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xticks(x + width, list(difficulty_data[list(difficulty_data.keys())[0]].keys()))\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize performance by problem type\n",
    "type_data = {model_name: {} for model_name in results.keys()}\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    # Collect results for each problem type\n",
    "    for problem_type in ['numeric', 'word']:\n",
    "        indices = test_df[test_df['type'] == problem_type].index\n",
    "        if model_name == \"T5 Pre-trained\":\n",
    "            type_predictions = [t5_predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        elif model_name == \"Zero-Shot GPT-2\":\n",
    "            type_predictions = [zs_predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        else:\n",
    "            type_predictions = [ft_predictions[i] for i in range(len(test_df)) if i in indices]\n",
    "        \n",
    "        type_references = [test_df.iloc[i]['solution'] for i in range(len(test_df)) if i in indices]\n",
    "        type_results = evaluate_model_predictions(type_predictions, type_references)\n",
    "        type_data[model_name][problem_type] = type_results['accuracy']\n",
    "\n",
    "# Create a grouped bar chart for problem type comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(type_data[list(type_data.keys())[0]]))\n",
    "width = 0.25\n",
    "multiplier = 0\n",
    "\n",
    "for model_name, types in type_data.items():\n",
    "    offset = width * multiplier\n",
    "    plt.bar(x + offset, list(types.values()), width, label=model_name)\n",
    "    multiplier += 1\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance by Problem Type')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xticks(x + width, list(type_data[list(type_data.keys())[0]].keys()))\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d420bf-d976-427f-afbc-a2bab52b231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## 6. Conclusion and Discussion\n",
    "\n",
    "We've explored three approaches to solving math problems with transformer models:\n",
    "\n",
    "1. **Pre-trained T5 Model**: We trained a sequence-to-sequence transformer model from the T5 family specifically for math problem solving. This model learns the task from scratch using our dataset.\n",
    "\n",
    "2. **Zero-Shot with GPT-2**: We used a small pre-trained language model (GPT-2) without any fine-tuning to solve math problems in a zero-shot manner. This shows the inherent mathematical capabilities of pre-trained language models.\n",
    "\n",
    "3. **Fine-tuned GPT-2 with LoRA**: We fine-tuned GPT-2 on our math problem dataset using LoRA, a parameter-efficient fine-tuning method that only trains a small number of adapter parameters.\n",
    "\n",
    "Key findings:\n",
    "\n",
    "1. **Performance Comparison**: \n",
    "   - Fine-tuned models generally perform best, showing the value of specialized training\n",
    "   - Zero-shot performance varies greatly by problem type and complexity\n",
    "   - All models struggle more with harder problems and word problems\n",
    "\n",
    "2. **Model Size vs. Performance**: \n",
    "   - Larger models generally perform better on more complex problems\n",
    "   - Even small models can perform well when fine-tuned on the specific task\n",
    "\n",
    "3. **Numeric vs. Word Problems**:\n",
    "   - Numeric problems are generally easier for all models\n",
    "   - Word problems require more language understanding and reasoning\n",
    "\n",
    "4. **Training Efficiency**:\n",
    "   - LoRA provides an efficient way to fine-tune models without updating all parameters\n",
    "   - The small adapter modules can capture the mathematical reasoning needed for this task\n",
    "\n",
    "## 7. Extension Ideas\n",
    "\n",
    "Here are some ways to extend this notebook:\n",
    "\n",
    "1. **Try larger models** like GPT-Neo, LLaMA, or Mistral to see how model scale affects performance\n",
    "\n",
    "2. **Explore chain-of-thought prompting** by formatting the training data to include step-by-step solutions\n",
    "\n",
    "3. **Add more problem types** such as algebra, geometry, or calculus problems\n",
    "\n",
    "4. **Implement a mixed approach** that combines transformer models with symbolic math libraries\n",
    "\n",
    "5. **Create an interactive demo** where users can input their own math problems and see the model's solution process\n",
    "\n",
    "6. **Analyze failure cases** to understand common errors and potential improvements\n",
    "\n",
    "7. **Experiment with instruction tuning** by reformulating the task as following instructions rather than simple completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0847ba2-0b89-418f-92ab-81040a86df0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b70981b-882b-405e-aa37-3e59d12c791f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
