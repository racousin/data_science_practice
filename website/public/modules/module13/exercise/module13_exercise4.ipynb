{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEAUjjhOb136"
   },
   "source": [
    "### Run in collab\n",
    "<a href=\"https://colab.research.google.com/github/racousin/data_science_practice/blob/master/website/public/modules/module13/exercise/module13_exercise4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVgWUZjpb137"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install swig==4.2.1\n",
    "!pip install gymnasium==0.29.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oa03cAjLb138"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJZwAAf2b139"
   },
   "source": [
    "# module13_exercise4 : ML - Arena <a href=\"https://ml-arena.com/viewcompetition/1\" target=\"_blank\"> LunarLander</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYQQPZhpb139"
   },
   "source": [
    "### Objective\n",
    "Get at list an agent running on ML-Arena <a href=\"https://ml-arena.com/viewcompetition/1\" target=\"_blank\"> LunarLander</a> with mean reward upper than 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should submit an agent file named `agent.py` with a class `Agent` that includes at least the following attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def choose_action(self, observation, reward=0.0, terminated=False, truncated=False, info=None):\n",
    "        action = self.env.action_space.sample() # your logic here\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This environment is a classic rocket trajectory optimization problem. According to Pontryagin’s maximum principle, it is optimal to fire the engine at full throttle or turn it off. This is the reason why this environment has discrete actions: engine on or off.\n",
    "There are two environment versions: discrete or continuous. The landing pad is always at coordinates (0,0). The coordinates are the first two numbers in the state vector. Landing outside of the landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt.\n",
    "\n",
    "### Action Space\n",
    "\n",
    "There are four discrete actions available:\n",
    "- 0: do nothing\n",
    "- 1: fire left orientation engine\n",
    "- 2: fire main engine\n",
    "- 3: fire right orientation engine\n",
    "\n",
    "### Observation Space\n",
    "The state is an 8-dimensional vector: the coordinates of the lander in x & y, its linear velocities in x & y, its angle, its angular velocity, and two booleans that represent whether each leg is in contact with the ground or not.\n",
    "\n",
    "### Rewards\n",
    "After every step a reward is granted. The total reward of an episode is the sum of the rewards for all the steps within that episode.\n",
    "For each step, the reward:\n",
    "- is increased/decreased the closer/further the lander is to the landing pad.\n",
    "- is increased/decreased the slower/faster the lander is moving.\n",
    "- is decreased the more the lander is tilted (angle not horizontal).\n",
    "- is increased by 10 points for each leg that is in contact with the ground.\n",
    "- is decreased by 0.03 points each frame a side engine is firing.\n",
    "- is decreased by 0.3 points each frame the main engine is firing.\n",
    "\n",
    "The episode receive an additional reward of -100 or +100 points for crashing or landing safely respectively.\n",
    "An episode is considered a solution if it scores at least 200 points.\n",
    "\n",
    "### Starting State\n",
    "The lander starts at the top center of the viewport with a random initial force applied to its center of mass.\n",
    "\n",
    "### Episode Termination\n",
    "The episode finishes if:\n",
    "- the lander crashes (the lander body gets in contact with the moon);\n",
    "- the lander gets outside of the viewport (x coordinate is greater than 1);\n",
    "- the lander is not awake. From the Box2D docs, a body which is not awake is a body which doesn’t move and doesn’t collide with any other body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before submit\n",
    "Test that your agent has the right attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "agent = Agent(env)\n",
    "\n",
    "observation, _ = env.reset()\n",
    "reward, terminated, truncated, info = None, False, False, None\n",
    "rewards = []\n",
    "while not (terminated or truncated):\n",
    "    action = agent.choose_action(observation, reward=reward, terminated=terminated, truncated=truncated, info=info)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    rewards.append(reward)\n",
    "print(f'Cumulative Reward: {sum(rewards)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
