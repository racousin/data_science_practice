{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f942bd5-6b21-4075-8623-9c5368383b77",
   "metadata": {},
   "source": [
    "### Exercise: Combining Data from Multiple Sources\n",
    "\n",
    "#### Objectives\n",
    "- Retrieve data from various sources: Excel, JSON, SQLite3, and web.\n",
    "- Join the data correctly on different IDs.\n",
    "- Return a combined dataframe with the correct IDs and answers.\n",
    "#### Data Sources\n",
    "\n",
    "1. **Excel File**: Contains user information with IDs.\n",
    "2. **JSON File**: Contains purchase data linked by user IDs.\n",
    "3. **SQLite3 Database**: Contains transaction details linked by transaction IDs.\n",
    "4. **Web Data**: Retrieve additional user details from a web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d887630-65b5-4bc5-aed7-ca7f1f30c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URLs of the files\n",
    "train_data_url = 'https://www.raphaelcousin.com/modules/module3/exercise/module4_exercise_train.csv'\n",
    "test_data_url = 'https://www.raphaelcousin.com/modules/module3/exercise/module4_exercise_test.csv'\n",
    "\n",
    "# Function to download a file\n",
    "def download_file(url, file_name):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure we notice bad responses\n",
    "    with open(file_name, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f'Downloaded {file_name} from {url}')\n",
    "\n",
    "# Downloading the files\n",
    "download_file(train_data_url, 'module4_exercise_train.csv')\n",
    "download_file(test_data_url, 'module4_exercise_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbcccd3-b0be-4945-acd2-721cc7f318ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step-by-Step Guide\n",
    "\n",
    "#### 1. Retrieve Data from Excel File\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file = 'users.xlsx'\n",
    "df_users = pd.read_excel(excel_file)\n",
    "\n",
    "# Display the dataframe\n",
    "df_users.head()\n",
    "```\n",
    "\n",
    "#### 2. Retrieve Data from JSON File\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "json_file = 'purchases.json'\n",
    "with open(json_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df_purchases = pd.DataFrame(data)\n",
    "\n",
    "# Display the dataframe\n",
    "df_purchases.head()\n",
    "```\n",
    "\n",
    "#### 3. Retrieve Data from SQLite3 Database\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite3 database\n",
    "conn = sqlite3.connect('transactions.db')\n",
    "\n",
    "# Query the database\n",
    "query = 'SELECT * FROM transactions'\n",
    "df_transactions = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the dataframe\n",
    "df_transactions.head()\n",
    "```\n",
    "\n",
    "#### 4. Retrieve Data from a Web Page\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# Web scraping additional user details\n",
    "url = 'https://example.com/user-details'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Assuming the web page returns JSON data\n",
    "web_data = response.json()\n",
    "df_web = pd.DataFrame(web_data)\n",
    "\n",
    "# Display the dataframe\n",
    "df_web.head()\n",
    "```\n",
    "\n",
    "#### 5. Combine Data from All Sources\n",
    "\n",
    "```python\n",
    "# Merge dataframes on appropriate IDs\n",
    "df_combined = df_users.merge(df_purchases, on='user_id') \\\n",
    "                      .merge(df_transactions, on='transaction_id') \\\n",
    "                      .merge(df_web, on='user_id')\n",
    "\n",
    "# Display the combined dataframe\n",
    "df_combined.head()\n",
    "```\n",
    "\n",
    "### Sample Data\n",
    "\n",
    "Here is some sample data to use in the exercise:\n",
    "\n",
    "1. **users.xlsx**:\n",
    "   | user_id | name  | age |\n",
    "   |---------|-------|-----|\n",
    "   | 1       | Alice | 30  |\n",
    "   | 2       | Bob   | 25  |\n",
    "   | 3       | Carol | 27  |\n",
    "\n",
    "2. **purchases.json**:\n",
    "   ```json\n",
    "   [\n",
    "       {\"user_id\": 1, \"transaction_id\": 100, \"item\": \"Laptop\"},\n",
    "       {\"user_id\": 2, \"transaction_id\": 101, \"item\": \"Phone\"},\n",
    "       {\"user_id\": 3, \"transaction_id\": 102, \"item\": \"Tablet\"}\n",
    "   ]\n",
    "   ```\n",
    "\n",
    "3. **transactions.db** (SQLite3 Database):\n",
    "   | transaction_id | amount | date       |\n",
    "   |----------------|--------|------------|\n",
    "   | 100            | 1200   | 2023-01-10 |\n",
    "   | 101            | 800    | 2023-01-15 |\n",
    "   | 102            | 600    | 2023-01-20 |\n",
    "\n",
    "4. **Web Data**:\n",
    "   ```json\n",
    "   [\n",
    "       {\"user_id\": 1, \"address\": \"123 Main St\"},\n",
    "       {\"user_id\": 2, \"address\": \"456 Maple Ave\"},\n",
    "       {\"user_id\": 3, \"address\": \"789 Oak Dr\"}\n",
    "   ]\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b4959-67b0-40f7-b992-f78b29a51985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Step 1: Retrieve Data from Excel File\n",
    "excel_file = 'users.xlsx'\n",
    "df_users = pd.read_excel(excel_file)\n",
    "\n",
    "# Step 2: Retrieve Data from JSON File\n",
    "json_file = 'purchases.json'\n",
    "with open(json_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "df_purchases = pd.DataFrame(data)\n",
    "\n",
    "# Step 3: Retrieve Data from SQLite3 Database\n",
    "conn = sqlite3.connect('transactions.db')\n",
    "query = 'SELECT * FROM transactions'\n",
    "df_transactions = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Step 4: Retrieve Data from a Web Page\n",
    "url = 'https://example.com/user-details'\n",
    "response = requests.get(url)\n",
    "web_data = response.json()\n",
    "df_web = pd.DataFrame(web_data)\n",
    "\n",
    "# Step 5: Combine Data from All Sources\n",
    "df_combined = df_users.merge(df_purchases, on='user_id') \\\n",
    "                      .merge(df_transactions, on='transaction_id') \\\n",
    "                      .merge(df_web, on='user_id')\n",
    "\n",
    "# Display the combined dataframe\n",
    "df_combined.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
