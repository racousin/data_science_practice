{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Face Generation with DCGAN\n\nThis notebook demonstrates **face generation** using a DCGAN (Deep Convolutional GAN) trained on CelebA.\n\n**What makes this fun:**\n- Train a GAN that generates realistic human faces\n- Watch the model learn facial features progressively\n- Fast training on GPU (~30 minutes for quality results)\n- Generate unlimited unique faces\n\n**Why DCGAN?** Stable architecture with convolutional layers, batch normalization, and proven effectiveness for image generation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "# !pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 1: Data Preparation\n\nWe'll use the CelebA dataset - 200k celebrity face images. The faces will be cropped, resized to 64x64, and normalized."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load CelebA dataset\nimage_size = 64\nbatch_size = 128\n\ntransform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.CenterCrop(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n])\n\n# Download CelebA dataset (this may take a few minutes the first time)\ntrain_dataset = torchvision.datasets.CelebA(\n    root='./data', \n    split='train',\n    download=True, \n    transform=transform\n)\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=2, \n    pin_memory=True\n)\n\nprint(f'Training samples: {len(train_dataset):,}')\nprint(f'Batches per epoch: {len(train_loader):,}')\nprint(f'Image shape: {train_dataset[0][0].shape}')\n\n# Visualize real samples\nsamples = next(iter(train_loader))[0][:64]\ngrid = make_grid(samples, nrow=8, normalize=True, value_range=(-1, 1))\nplt.figure(figsize=(12, 12))\nplt.imshow(grid.permute(1, 2, 0).cpu())\nplt.title('Real CelebA Face Images', fontsize=16)\nplt.axis('off')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 2: Build DCGAN\n\nDCGAN uses deep convolutional layers with batch normalization for stable training. No fully connected layers!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class Generator(nn.Module):\n    \"\"\"\n    DCGAN Generator for 64x64 RGB images.\n    Architecture: latent vector -> 4x4 -> 8x8 -> 16x16 -> 32x32 -> 64x64\n    \"\"\"\n    def __init__(self, latent_dim=100, ngf=64):\n        super().__init__()\n        self.latent_dim = latent_dim\n        \n        self.main = nn.Sequential(\n            # Input: latent_dim x 1 x 1\n            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # State: (ngf*8) x 4 x 4\n            \n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # State: (ngf*4) x 8 x 8\n            \n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # State: (ngf*2) x 16 x 16\n            \n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # State: (ngf) x 32 x 32\n            \n            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # Output: 3 x 64 x 64\n        )\n    \n    def forward(self, noise):\n        return self.main(noise)\n\n\nclass Discriminator(nn.Module):\n    \"\"\"\n    DCGAN Discriminator for 64x64 RGB images.\n    Architecture: 64x64 -> 32x32 -> 16x16 -> 8x8 -> 4x4 -> 1\n    \"\"\"\n    def __init__(self, ndf=64):\n        super().__init__()\n        \n        self.main = nn.Sequential(\n            # Input: 3 x 64 x 64\n            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # State: (ndf) x 32 x 32\n            \n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # State: (ndf*2) x 16 x 16\n            \n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # State: (ndf*4) x 8 x 8\n            \n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # State: (ndf*8) x 4 x 4\n            \n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n            # Output: 1 x 1 x 1\n        )\n    \n    def forward(self, image):\n        return self.main(image).view(-1, 1)\n\n\n# Initialize models\ngenerator = Generator(latent_dim=100, ngf=64).to(device)\ndiscriminator = Discriminator(ndf=64).to(device)\n\n# Initialize weights (DCGAN paper recommendation)\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n\ngenerator.apply(weights_init)\ndiscriminator.apply(weights_init)\n\nprint(f'Generator parameters: {sum(p.numel() for p in generator.parameters()):,}')\nprint(f'Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Loss and optimizers\ncriterion = nn.BCELoss()\noptimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n# Fixed noise for visualization (100 samples)\nfixed_noise = torch.randn(64, generator.latent_dim, 1, 1).to(device)\n\nprint('Training setup complete!')\nprint(f'Fixed noise shape: {fixed_noise.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training function\ndef train_epoch(generator, discriminator, loader, optimizer_g, optimizer_d, criterion, device):\n    generator.train()\n    discriminator.train()\n    \n    d_losses = []\n    g_losses = []\n    \n    for real_images, _ in tqdm(loader, desc='Training'):\n        batch_size = real_images.size(0)\n        real_images = real_images.to(device)\n        \n        # Labels for real and fake\n        real_labels = torch.ones(batch_size, 1).to(device)\n        fake_labels = torch.zeros(batch_size, 1).to(device)\n        \n        # ============================================\n        # Train Discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n        # ============================================\n        optimizer_d.zero_grad()\n        \n        # Real images\n        real_output = discriminator(real_images)\n        d_loss_real = criterion(real_output, real_labels)\n        \n        # Fake images\n        noise = torch.randn(batch_size, generator.latent_dim, 1, 1).to(device)\n        fake_images = generator(noise)\n        fake_output = discriminator(fake_images.detach())\n        d_loss_fake = criterion(fake_output, fake_labels)\n        \n        # Total discriminator loss\n        d_loss = d_loss_real + d_loss_fake\n        d_loss.backward()\n        optimizer_d.step()\n        \n        # ============================================\n        # Train Generator: maximize log(D(G(z)))\n        # ============================================\n        optimizer_g.zero_grad()\n        \n        # Generate fake images\n        noise = torch.randn(batch_size, generator.latent_dim, 1, 1).to(device)\n        fake_images = generator(noise)\n        fake_output = discriminator(fake_images)\n        \n        # Generator wants discriminator to think fakes are real\n        g_loss = criterion(fake_output, real_labels)\n        g_loss.backward()\n        optimizer_g.step()\n        \n        d_losses.append(d_loss.item())\n        g_losses.append(g_loss.item())\n    \n    return np.mean(d_losses), np.mean(g_losses)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 4: Train the GAN\n\nWatch the generated faces improve progressively! Early epochs will show blurry faces, later epochs will show realistic features."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "epochs = 20\nsample_interval = 2  # Show samples every N epochs\n\nhistory = {'d_loss': [], 'g_loss': []}\n\nfor epoch in range(epochs):\n    print(f'\\n=== Epoch {epoch+1}/{epochs} ===')\n    \n    d_loss, g_loss = train_epoch(generator, discriminator, train_loader, \n                                  optimizer_g, optimizer_d, criterion, device)\n    \n    history['d_loss'].append(d_loss)\n    history['g_loss'].append(g_loss)\n    \n    print(f'D Loss: {d_loss:.4f} | G Loss: {g_loss:.4f}')\n    \n    # Generate samples at intervals\n    if (epoch + 1) % sample_interval == 0 or epoch == 0:\n        generator.eval()\n        with torch.no_grad():\n            fake_images = generator(fixed_noise)\n        \n        grid = make_grid(fake_images, nrow=8, normalize=True, value_range=(-1, 1))\n        plt.figure(figsize=(10, 10))\n        plt.imshow(grid.permute(1, 2, 0).cpu())\n        plt.title(f'Generated Faces - Epoch {epoch+1}', fontsize=16)\n        plt.axis('off')\n        plt.tight_layout()\n        plt.show()\n\nprint('\\nTraining complete!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['d_loss'], label='Discriminator Loss', linewidth=2)\n",
    "plt.plot(history['g_loss'], label='Generator Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training Loss Over Time', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 5: Generate More Faces\n\nGenerate new random faces on demand!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_faces(num_samples=16):\n    \"\"\"\n    Generate random faces.\n    \n    Args:\n        num_samples: Number of faces to generate\n    \"\"\"\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(num_samples, generator.latent_dim, 1, 1).to(device)\n        generated = generator(noise)\n    \n    grid = make_grid(generated, nrow=4, normalize=True, value_range=(-1, 1))\n    plt.figure(figsize=(8, 8))\n    plt.imshow(grid.permute(1, 2, 0).cpu())\n    plt.title(f'Generated Faces', fontsize=16)\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Generate multiple batches\nprint('Generating random faces...')\nfor i in range(3):\n    print(f'\\nBatch {i+1}:')\n    generate_faces(num_samples=16)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 6: Generate High-Resolution Grid\n\nCreate a large grid showing the variety of generated faces."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate a large grid of faces\ngenerator.eval()\nnum_faces = 64\n\nwith torch.no_grad():\n    noise = torch.randn(num_faces, generator.latent_dim, 1, 1).to(device)\n    generated_faces = generator(noise)\n\ngrid = make_grid(generated_faces, nrow=8, normalize=True, value_range=(-1, 1))\nplt.figure(figsize=(15, 15))\nplt.imshow(grid.permute(1, 2, 0).cpu())\nplt.title('Generated Face Gallery (64 unique faces)', fontsize=18)\nplt.axis('off')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Latent Space Exploration\n",
    "\n",
    "Interpolate between two random points in latent space for the same digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def interpolate_latent(num_steps=10):\n    \"\"\"\n    Interpolate between two random latent vectors to show smooth transitions.\n    \"\"\"\n    generator.eval()\n    \n    # Two random starting points\n    z1 = torch.randn(1, generator.latent_dim, 1, 1).to(device)\n    z2 = torch.randn(1, generator.latent_dim, 1, 1).to(device)\n    \n    interpolations = []\n    with torch.no_grad():\n        for alpha in torch.linspace(0, 1, num_steps):\n            z = (1 - alpha) * z1 + alpha * z2\n            img = generator(z)\n            interpolations.append(img)\n    \n    interpolations = torch.cat(interpolations)\n    grid = make_grid(interpolations, nrow=num_steps, normalize=True, value_range=(-1, 1))\n    \n    plt.figure(figsize=(15, 3))\n    plt.imshow(grid.permute(1, 2, 0).cpu())\n    plt.title(f'Latent Space Interpolation (smooth transitions)', fontsize=14)\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Show multiple interpolations\nprint('Latent space interpolation - watch faces morph smoothly!')\nfor i in range(3):\n    print(f'\\nInterpolation {i+1}:')\n    interpolate_latent(num_steps=10)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n**What we accomplished:**\n1. Built a DCGAN that generates realistic 64x64 RGB face images\n2. Trained on CelebA dataset (~200k celebrity faces)\n3. Generated unlimited unique faces from random noise\n4. Explored smooth latent space interpolations\n\n**Key Takeaways:**\n- **DCGAN architecture** uses only convolutional layers (no fully connected)\n- **Batch normalization** stabilizes training\n- **LeakyReLU** in discriminator, **ReLU** in generator\n- **Tanh activation** outputs images in [-1, 1] range\n- GANs learn complex distributions through adversarial training\n\n**DCGAN Architecture Benefits:**\n- No spatial pooling (uses strided convolutions)\n- Batch normalization in both networks\n- No fully connected hidden layers\n- ReLU activation in generator (except output uses Tanh)\n- LeakyReLU activation in discriminator\n\n**Why This Matters:**\n- **Data augmentation**: Generate synthetic training data\n- **Creative applications**: Art, design, game character generation\n- **Research tool**: Understand facial feature distributions\n- **Privacy**: Generate synthetic faces instead of using real photos\n\n**Next Steps:**\n- Train longer for higher quality (50+ epochs)\n- Try Progressive GAN or StyleGAN for higher resolution\n- Experiment with different architectures (bigger networks)\n- Try modern alternatives like Diffusion Models\n- Explore conditional generation (add attributes control)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}