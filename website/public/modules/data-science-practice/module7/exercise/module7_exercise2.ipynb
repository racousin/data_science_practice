{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Cat Face Generation with Generative Models\n",
    "\n",
    "In this exercise, you will build a generative model to create synthetic cat faces. You can choose between VAE, GAN, or Diffusion models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-download",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "Download and extract the cats faces dataset (64x64 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset URL from Kaggle (direct download)\n",
    "# Note: You may need to download manually from:\n",
    "# https://www.kaggle.com/datasets/spandan2/cats-faces-64x64-for-generative-models\n",
    "\n",
    "# For this exercise, we'll assume you have downloaded and extracted the dataset\n",
    "data_dir = 'cats_dataset'  # Update this path to your dataset location\n",
    "\n",
    "# If you have the dataset as a zip file, uncomment to extract:\n",
    "# with zipfile.ZipFile('cats-faces-64x64.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall(data_dir)\n",
    "\n",
    "print(f\"Dataset directory: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the cat face images into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cat_images(data_dir, max_images=None):\n",
    "    \"\"\"\n",
    "    Load cat face images from directory\n",
    "    Returns: numpy array of shape (n_samples, 64, 64, 3)\n",
    "    \"\"\"\n",
    "    image_files = list(Path(data_dir).glob('*.jpg')) + list(Path(data_dir).glob('*.png'))\n",
    "    \n",
    "    if max_images:\n",
    "        image_files = image_files[:max_images]\n",
    "    \n",
    "    images = []\n",
    "    for img_path in image_files:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize((64, 64))  # Ensure 64x64\n",
    "        images.append(np.array(img))\n",
    "    \n",
    "    return np.array(images)\n",
    "\n",
    "# Load images\n",
    "images = load_cat_images(data_dir)\n",
    "print(f\"Loaded {len(images)} images\")\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "print(f\"Data type: {images.dtype}\")\n",
    "print(f\"Value range: [{images.min()}, {images.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Display sample cat face images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 12 sample images\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(12):\n",
    "    axes[i].imshow(images[i])\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Image {i}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-prep",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Normalize images and prepare for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to [0, 1] range\n",
    "images_normalized = images.astype('float32') / 255.0\n",
    "\n",
    "# For some models (like GANs), you may want [-1, 1] range:\n",
    "# images_normalized = (images.astype('float32') - 127.5) / 127.5\n",
    "\n",
    "print(f\"Normalized shape: {images_normalized.shape}\")\n",
    "print(f\"Normalized range: [{images_normalized.min():.3f}, {images_normalized.max():.3f}]\")\n",
    "\n",
    "# Split into train/validation sets\n",
    "split_idx = int(0.9 * len(images_normalized))\n",
    "train_images = images_normalized[:split_idx]\n",
    "val_images = images_normalized[split_idx:]\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_images)}\")\n",
    "print(f\"Validation samples: {len(val_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-choice",
   "metadata": {},
   "source": [
    "## Build Your Generative Model\n",
    "\n",
    "Choose one of the following approaches:\n",
    "\n",
    "### Option 1: Variational Autoencoder (VAE)\n",
    "- Build an encoder to map images to latent space\n",
    "- Build a decoder to reconstruct images from latent vectors\n",
    "- Use VAE loss (reconstruction + KL divergence)\n",
    "- Generate new cats by sampling from latent space\n",
    "\n",
    "### Option 2: Generative Adversarial Network (GAN)\n",
    "- Build a generator to create images from noise\n",
    "- Build a discriminator to distinguish real from fake\n",
    "- Train adversarially using minimax loss\n",
    "- Generate new cats from random noise vectors\n",
    "\n",
    "### Option 3: Diffusion Model\n",
    "- Define forward diffusion process (adding noise)\n",
    "- Build a U-Net to predict noise\n",
    "- Train to denoise images at different timesteps\n",
    "- Generate new cats through reverse diffusion\n",
    "\n",
    "Implement your chosen model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your deep learning framework\n",
    "# Example for PyTorch:\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Example for TensorFlow/Keras:\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architecture here\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generation",
   "metadata": {},
   "source": [
    "## Generate New Cat Faces\n",
    "\n",
    "Use your trained model to generate synthetic cat faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new cat faces\n",
    "# Your code here\n",
    "\n",
    "# Example visualization:\n",
    "# fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "# axes = axes.flatten()\n",
    "# \n",
    "# for i in range(12):\n",
    "#     axes[i].imshow(generated_images[i])\n",
    "#     axes[i].axis('off')\n",
    "#     axes[i].set_title(f'Generated {i}')\n",
    "# \n",
    "# plt.suptitle('Generated Cat Faces')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-model",
   "metadata": {},
   "source": [
    "## Save Your Results\n",
    "\n",
    "Save your trained model and generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "# Your code here\n",
    "\n",
    "# Save generated images as a grid\n",
    "# Your code here\n",
    "\n",
    "print(\"Model and results saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
