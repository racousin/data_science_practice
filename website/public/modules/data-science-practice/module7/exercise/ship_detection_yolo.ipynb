{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ship Detection with YOLO Fine-tuning\n",
    "## Complete Pipeline: Download → Split → Train → Evaluate\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Downloading the Kaggle ship detection dataset\n",
    "2. Creating train/test splits\n",
    "3. Fine-tuning YOLOv8 on the dataset\n",
    "4. Evaluating results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub ultralytics opencv-python matplotlib pillow xmltodict scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrewmvd/ship-detection\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# List files in the dataset\n",
    "print(\"\\nDataset contents:\")\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files[:10]:  # Show first 10 files\n",
    "        print(f\"  {file}\")\n",
    "    if len(files) > 10:\n",
    "        print(f\"  ... and {len(files) - 10} more files\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find all images and annotations\n",
    "images = glob.glob(os.path.join(path, \"**/*.png\"), recursive=True) + \\\n",
    "         glob.glob(os.path.join(path, \"**/*.jpg\"), recursive=True)\n",
    "annotations = glob.glob(os.path.join(path, \"**/*.xml\"), recursive=True)\n",
    "\n",
    "print(f\"Total images found: {len(images)}\")\n",
    "print(f\"Total annotations found: {len(annotations)}\")\n",
    "\n",
    "# Display a sample image\n",
    "if images:\n",
    "    sample_img = Image.open(images[0])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(sample_img)\n",
    "    plt.title(\"Sample Ship Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f\"Image size: {sample_img.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert Pascal VOC XML to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_voc_to_yolo(xml_file, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert Pascal VOC bounding box to YOLO format.\n",
    "    YOLO format: <class_id> <x_center> <y_center> <width> <height>\n",
    "    All values normalized to [0, 1]\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    yolo_annotations = []\n",
    "    \n",
    "    for obj in root.findall('object'):\n",
    "        # Class is always 0 for 'boat' in this dataset\n",
    "        class_id = 0\n",
    "        \n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = float(bbox.find('xmin').text)\n",
    "        ymin = float(bbox.find('ymin').text)\n",
    "        xmax = float(bbox.find('xmax').text)\n",
    "        ymax = float(bbox.find('ymax').text)\n",
    "        \n",
    "        # Convert to YOLO format (normalized)\n",
    "        x_center = ((xmin + xmax) / 2.0) / img_width\n",
    "        y_center = ((ymin + ymax) / 2.0) / img_height\n",
    "        width = (xmax - xmin) / img_width\n",
    "        height = (ymax - ymin) / img_height\n",
    "        \n",
    "        yolo_annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "    \n",
    "    return yolo_annotations\n",
    "\n",
    "print(\"Conversion function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Train/Test Split and Organize for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# Create YOLO directory structure\n",
    "dataset_root = Path(\"ship_yolo_dataset\")\n",
    "dataset_root.mkdir(exist_ok=True)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    (dataset_root / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (dataset_root / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Match images with their annotations\n",
    "image_annotation_pairs = []\n",
    "for img_path in images:\n",
    "    base_name = Path(img_path).stem\n",
    "    # Find corresponding XML annotation\n",
    "    xml_path = None\n",
    "    for ann in annotations:\n",
    "        if Path(ann).stem == base_name:\n",
    "            xml_path = ann\n",
    "            break\n",
    "    \n",
    "    if xml_path:\n",
    "        image_annotation_pairs.append((img_path, xml_path))\n",
    "\n",
    "print(f\"Found {len(image_annotation_pairs)} image-annotation pairs\")\n",
    "\n",
    "# Split into train (80%) and validation (20%)\n",
    "train_pairs, val_pairs = train_test_split(image_annotation_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_pairs)}\")\n",
    "print(f\"Validation samples: {len(val_pairs)}\")\n",
    "\n",
    "def process_and_copy_data(pairs, split_name):\n",
    "    \"\"\"Process image-annotation pairs and copy to YOLO format\"\"\"\n",
    "    for img_path, xml_path in pairs:\n",
    "        # Read image to get dimensions\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Convert annotation to YOLO format\n",
    "        yolo_annotations = convert_voc_to_yolo(xml_path, width, height)\n",
    "        \n",
    "        # Copy image\n",
    "        base_name = Path(img_path).stem\n",
    "        img_ext = Path(img_path).suffix\n",
    "        dest_img = dataset_root / split_name / 'images' / f\"{base_name}{img_ext}\"\n",
    "        shutil.copy2(img_path, dest_img)\n",
    "        \n",
    "        # Save YOLO annotation\n",
    "        dest_label = dataset_root / split_name / 'labels' / f\"{base_name}.txt\"\n",
    "        with open(dest_label, 'w') as f:\n",
    "            f.write('\\n'.join(yolo_annotations))\n",
    "\n",
    "print(\"\\nProcessing training data...\")\n",
    "process_and_copy_data(train_pairs, 'train')\n",
    "\n",
    "print(\"Processing validation data...\")\n",
    "process_and_copy_data(val_pairs, 'val')\n",
    "\n",
    "print(\"\\n✅ Dataset preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create YOLO Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Create YOLO data configuration\n",
    "data_config = {\n",
    "    'path': str(dataset_root.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'names': {\n",
    "        0: 'boat'\n",
    "    },\n",
    "    'nc': 1  # number of classes\n",
    "}\n",
    "\n",
    "config_path = 'ship_data.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(data_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Configuration saved to {config_path}\")\n",
    "print(\"\\nConfiguration content:\")\n",
    "print(yaml.dump(data_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Some Training Samples with Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import random\n",
    "\n",
    "def visualize_yolo_annotations(img_path, label_path, num_samples=3):\n",
    "    \"\"\"Visualize images with YOLO bounding boxes\"\"\"\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    train_images = list((dataset_root / 'train' / 'images').glob('*'))\n",
    "    samples = random.sample(train_images, min(num_samples, len(train_images)))\n",
    "    \n",
    "    for ax, img_file in zip(axes, samples):\n",
    "        # Read image\n",
    "        img = Image.open(img_file)\n",
    "        width, height = img.size\n",
    "        \n",
    "        # Read corresponding label\n",
    "        label_file = dataset_root / 'train' / 'labels' / f\"{img_file.stem}.txt\"\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        \n",
    "        if label_file.exists():\n",
    "            with open(label_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    # Parse YOLO format\n",
    "                    class_id, x_center, y_center, w, h = map(float, line.strip().split())\n",
    "                    \n",
    "                    # Convert back to pixel coordinates\n",
    "                    x_center *= width\n",
    "                    y_center *= height\n",
    "                    w *= width\n",
    "                    h *= height\n",
    "                    \n",
    "                    # Calculate corner coordinates\n",
    "                    x1 = x_center - w/2\n",
    "                    y1 = y_center - h/2\n",
    "                    \n",
    "                    # Draw bounding box\n",
    "                    rect = patches.Rectangle((x1, y1), w, h, linewidth=2, \n",
    "                                            edgecolor='red', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "        \n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Sample: {img_file.name}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_yolo_annotations(None, None, num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fine-tune YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model (nano version for faster training)\n",
    "model = YOLO('yolov8n.pt')  # yolov8n = nano (smallest/fastest)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model architecture: {model.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "results = model.train(\n",
    "    data=config_path,           # Path to data config\n",
    "    epochs=50,                   # Number of epochs (adjust based on your needs)\n",
    "    imgsz=640,                   # Image size\n",
    "    batch=16,                    # Batch size (reduce if out of memory)\n",
    "    name='ship_detection',       # Experiment name\n",
    "    patience=10,                 # Early stopping patience\n",
    "    save=True,                   # Save checkpoints\n",
    "    plots=True,                  # Generate training plots\n",
    "    device='cuda' if __import__('torch').cuda.is_available() else 'cpu'  # Use GPU if available\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "metrics = model.val()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\n=== Evaluation Results ===\")\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")        # mAP at IoU=0.5\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")       # mAP at IoU=0.5:0.95\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "# Display training curves\n",
    "results_dir = Path('runs/detect/ship_detection')\n",
    "\n",
    "print(\"Training Results:\")\n",
    "print(\"\\n1. Results Plot:\")\n",
    "display(IPImage(filename=str(results_dir / 'results.png')))\n",
    "\n",
    "print(\"\\n2. Confusion Matrix:\")\n",
    "if (results_dir / 'confusion_matrix.png').exists():\n",
    "    display(IPImage(filename=str(results_dir / 'confusion_matrix.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Test Predictions on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "best_model = YOLO('runs/detect/ship_detection/weights/best.pt')\n",
    "\n",
    "# Get some validation images\n",
    "val_images = list((dataset_root / 'val' / 'images').glob('*'))[:5]\n",
    "\n",
    "# Run inference\n",
    "print(\"Running predictions on sample validation images...\\n\")\n",
    "\n",
    "for img_path in val_images:\n",
    "    results = best_model.predict(source=str(img_path), save=True, conf=0.25)\n",
    "    \n",
    "    # Display results\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        print(f\"Image: {img_path.name}\")\n",
    "        print(f\"  Detected {len(boxes)} boat(s)\")\n",
    "        for box in boxes:\n",
    "            conf = box.conf[0]\n",
    "            print(f\"    - Confidence: {conf:.2f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nPredictions saved to: runs/detect/predict/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Display Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display predictions\n",
    "predict_dir = Path('runs/detect/predict')\n",
    "predicted_images = list(predict_dir.glob('*.png')) + list(predict_dir.glob('*.jpg'))\n",
    "\n",
    "if predicted_images:\n",
    "    num_display = min(3, len(predicted_images))\n",
    "    fig, axes = plt.subplots(1, num_display, figsize=(15, 5))\n",
    "    if num_display == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, img_path in zip(axes, predicted_images[:num_display]):\n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Prediction: {img_path.name}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No prediction images found. Check the predict directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Save Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "print(\"\\n=== Model Summary ===\")\n",
    "print(f\"Model: YOLOv8n (nano)\")\n",
    "print(f\"Dataset: Ship Detection (Kaggle)\")\n",
    "print(f\"Training samples: {len(train_pairs)}\")\n",
    "print(f\"Validation samples: {len(val_pairs)}\")\n",
    "print(f\"Number of classes: 1 (boat)\")\n",
    "print(f\"Best model saved at: runs/detect/ship_detection/weights/best.pt\")\n",
    "print(f\"\\nFinal metrics:\")\n",
    "print(f\"  mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Complete!\n",
    "\n",
    "### What you've accomplished:\n",
    "1. ✅ Downloaded ship detection dataset from Kaggle\n",
    "2. ✅ Converted annotations from Pascal VOC to YOLO format\n",
    "3. ✅ Created train/validation split (80/20)\n",
    "4. ✅ Fine-tuned YOLOv8 on ship detection\n",
    "5. ✅ Evaluated the model performance\n",
    "6. ✅ Visualized predictions\n",
    "\n",
    "### Next steps for students:\n",
    "- Experiment with different YOLO models (yolov8s, yolov8m, yolov8l)\n",
    "- Adjust hyperparameters (epochs, batch size, learning rate)\n",
    "- Try data augmentation techniques\n",
    "- Test on their own ship images\n",
    "- Compare with other object detection models (Faster R-CNN, RetinaNet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
